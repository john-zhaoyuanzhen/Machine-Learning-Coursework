{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Coursework"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tensorflow.keras.datasets import mnist #to import our dataset\n",
    "from tensorflow.keras.models import Sequential, Model # imports our type of network\n",
    "from tensorflow.keras.layers import Dense, Flatten, Input, Dropout # imports our layers we want to use\n",
    "\n",
    "from tensorflow.python.keras.losses import categorical_crossentropy #loss function\n",
    "from tensorflow.keras.optimizers import Adam #optimisers\n",
    "from tensorflow.keras.utils import to_categorical #some function for data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "num_classes = 19\n",
    "epochs = 20\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "x_train /= 255\n",
    "x_test /= 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "images = np.concatenate((x_train, x_test), axis=0)\n",
    "labels = np.concatenate((y_train, y_test), axis=0)\n",
    "\n",
    "np.random.seed(114514)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_combined_dataset(iamges, labels, dataset_size=10000):\n",
    "    combined_images = []\n",
    "    combined_labels = []\n",
    "    \n",
    "    for _ in range(dataset_size):\n",
    "        idx1, idx2 = np.random.choice(np.arange(len(images)), 2, replace=True)\n",
    "        img1, img2 = images[idx1], images[idx2]\n",
    "        label1, label2 = labels[idx1], labels[idx2]\n",
    "        \n",
    "        combined_image = np.hstack((img1, img2))\n",
    "        combined_label = label1 + label2\n",
    "        \n",
    "        combined_images.append(combined_image)\n",
    "        combined_labels.append(combined_label)\n",
    "        \n",
    "    combined_images = np.array(combined_images).reshape(-1, 28, 56, 1)\n",
    "    combined_labels = np.array(combined_labels)\n",
    "    \n",
    "    return combined_images, combined_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size:  60000\n",
      "Validation size:  20000\n",
      "Test size:  20000\n"
     ]
    }
   ],
   "source": [
    "dataset_size = 100000\n",
    "train_size = int(0.6 * dataset_size)\n",
    "val_size = int(0.2 * dataset_size)\n",
    "test_size = dataset_size - train_size - val_size\n",
    "\n",
    "print(\"Train size: \", train_size)\n",
    "print(\"Validation size: \", val_size)\n",
    "print(\"Test size: \", test_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_images, combined_labels = create_combined_dataset(images, labels, dataset_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(28, 56, 1)\n",
      "10\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x2413c969550>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAh8AAAEkCAYAAACPCFMiAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjkuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8hTgPZAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAdOklEQVR4nO3df3CU1d338c+SkAU02RBCfknAIAIqEu4ixIw/ipISIjqg2FHLOGhbuaXBiqmPNR0F0c7EH32UYlPwVgv1uUUUp8CIFotRQm0JhUhupNVIaCrxgYRqSxKChJic5w8ft26Ne/Jjcza7eb9mrpnkOt+c65tjMJ+5cu1ZjzHGCAAAwJFB4W4AAAAMLIQPAADgFOEDAAA4RfgAAABOET4AAIBThA8AAOAU4QMAADhF+AAAAE7FhruBf9fR0aEjR44oPj5eHo8n3O0AAIAuMMaoublZGRkZGjQo+L2Nfhc+jhw5oszMzHC3AQAAeqCurk6jRo0KWtNn4aO0tFSPPfaY6uvrlZ2drSeffFLTp0+3fl18fLwk6VJdpVgN7qv2AABACH2mNr2t1/y/x4Ppk/Dx4osvqqioSGvWrFFOTo5Wrlyp/Px8VVdXKyUlJejXfvGnllgNVqyH8AEAQET4/+8U15VHJvrkgdPHH39ct912m2699Vadf/75WrNmjYYNG6Zf/epXfXE5AAAQQUIePk6fPq3Kykrl5eX96yKDBikvL0+7du36Sn1ra6uampoCDgAAEL1CHj4+/vhjtbe3KzU1NeB8amqq6uvrv1JfUlIin8/nP3jYFACA6Bb2fT6Ki4vV2NjoP+rq6sLdEgAA6EMhf+A0OTlZMTExamhoCDjf0NCgtLS0r9R7vV55vd5QtwEAAPqpkN/5iIuL09SpU1VWVuY/19HRobKyMuXm5ob6cgAAIML0yUtti4qKtHDhQl100UWaPn26Vq5cqZaWFt166619cTkAABBB+iR83HDDDfr73/+uZcuWqb6+XlOmTNG2bdu+8hAqAAAYeDzGGBPuJr6sqalJPp9PMzSXTcYAAIgQn5k27dAWNTY2KiEhIWht2F/tAgAABhbCBwAAcIrwAQAAnCJ8AAAApwgfAADAKcIHAABwivABAACcInwAAACnCB8AAMApwgcAAHCK8AEAAJwifAAAAKcIHwAAwCnCBwAAcCo23A0AA1XMhHHWmsJXt1prHvrgamuN76qaLvUEAC5w5wMAADhF+AAAAE4RPgAAgFOEDwAA4BThAwAAOEX4AAAAThE+AACAU4QPAADgFJuMAX3gwwdzrTXvf391SK71UEhmAQB3uPMBAACcInwAAACnCB8AAMApwgcAAHCK8AEAAJwifAAAAKcIHwAAwCn2+QC6yeUeHj88Ms1ak3SXfZ72EPQCAKHCnQ8AAOBUyMPHAw88II/HE3BMnDgx1JcBAAARqk/+7HLBBRfojTfe+NdFYvnrDgAA+FyfpILY2FilpaX1xdQAACDC9ckzHwcPHlRGRobGjh2rBQsW6PDhw19b29raqqampoADAABEr5CHj5ycHK1bt07btm3T6tWrVVtbq8suu0zNzc2d1peUlMjn8/mPzMzMULcEAAD6kZCHj4KCAn3729/W5MmTlZ+fr9dee03Hjx/XSy+91Gl9cXGxGhsb/UddXV2oWwIAAP1Inz8JmpiYqPHjx6umpqbTca/XK6/X29dtAACAfqLPw8eJEyd06NAh3XzzzX19KcAqZsK4oOPjnv/QOsfrGaHZQGziM4utNWOW7erCTJ0HewDor0L+Z5e7775b5eXl+tvf/qY//vGPuvbaaxUTE6Obbrop1JcCAAARKOR3Pj766CPddNNN+uSTTzRy5Ehdeumlqqio0MiRI0N9KQAAEIFCHj42bNgQ6ikBAEAU4b1dAACAU4QPAADgFOEDAAA4RfgAAABOET4AAIBTvNc9osaHD+Zaa97/fu83CAvV5mBj1JUNxIDwiEkeYa1575Esa03aG/ZfMwkvVHSpp2gTc+5Ya03cMy3WmtFn/CPoePVFbV3uyRXufAAAAKcIHwAAwCnCBwAAcIrwAQAAnCJ8AAAApwgfAADAKcIHAABwivABAACcYpMxhF3MhHHWmnHPf2iteT3DvoHYqyeHBB0vnXO1dY4x1WwOhuhX990J1pqa2b+w1lx+1vX2i73QlY4iS+yos6w1szdXWmt+kFhrrcn9SWHQ8eH9cEND7nwAAACnCB8AAMApwgcAAHCK8AEAAJwifAAAAKcIHwAAwCnCBwAAcIrwAQAAnGKTMfSpj/8z11pTudy+OVhXZL16m7Vm/G17LBU1IekF6M9OXpdjrXls0bPWmqaOU9aa9v9O6UJHf+1CTf8Rc+5Ya80HKxKsNZsT7d939qo7rDWZL/9P0PEO6wzucecDAAA4RfgAAABOET4AAIBThA8AAOAU4QMAADhF+AAAAE4RPgAAgFOEDwAA4BSbjKHHXG4gdnHV9daa8372T2tNeyiaAfq5xgUXBx3/yQPPWef41tBPrTXn/f52a03Wf1dYa/oTT6z912L1cp+1Ztdlv7DW5D5wt7XmrKf/aK3pj5uI2XDnAwAAONXt8LFz505dc801ysjIkMfj0ebNmwPGjTFatmyZ0tPTNXToUOXl5engwYOh6hcAAES4boePlpYWZWdnq7S0tNPxRx99VKtWrdKaNWu0e/dunXHGGcrPz9epU/b3AAAAANGv2898FBQUqKCgoNMxY4xWrlyp++67T3PnzpUkPffcc0pNTdXmzZt14403fuVrWltb1dra6v+8qampuy0BAIAIEtJnPmpra1VfX6+8vDz/OZ/Pp5ycHO3atavTrykpKZHP5/MfmZmZoWwJAAD0MyENH/X19ZKk1NTUgPOpqan+sX9XXFysxsZG/1FXVxfKlgAAQD8T9pfaer1eeb3ecLcBAAAcCemdj7S0NElSQ0NDwPmGhgb/GAAAGNhCeucjKytLaWlpKisr05QpUyR9/gDp7t27tXjx4lBeCn3M5QZiU1fYfzaSn+r8maEvYwMxDASe/7jAWnPHso1Bx+cMO2Gd42f/mGCtOee7NdaaSNsAq/oX37DW1FyxxlrzbNO51poRT9v/vxatuh0+Tpw4oZqaf/3A1dbWqqqqSklJSRo9erSWLl2qn/70pzr33HOVlZWl+++/XxkZGZo3b14o+wYAABGq2+Fj7969uuKKK/yfFxUVSZIWLlyodevW6Z577lFLS4sWLVqk48eP69JLL9W2bds0ZMiQ0HUNAAAiVrfDx4wZM2SM+dpxj8ejBx98UA8++GCvGgMAANGJ93YBAABOET4AAIBThA8AAOAU4QMAADhF+AAAAE6FfXt1hEfMhHFBx0O1gdhVV1xvrUmuHrgb7QBfdvK6HGvN/3rk/1hrurKJmM21CVXWmjVPLLXWDN9n/zXTdI69n4RD9hqb1uEea83rBY91Yaah1orxcZ2/n9mXxY6Zaq357MPofL8z7nwAAACnCB8AAMApwgcAAHCK8AEAAJwifAAAAKcIHwAAwCnCBwAAcIrwAQAAnGKTsQGq8NWtvZ7jh0emWWv+8YR9nrYtub3uRZKSn2KzMvRfHzxt//fy/lW/sNbEKiYU7VidE2vfSKvm6qfsE10dgmacsn/fH7Sdstbcsfpua03Gh3/sUkfRiDsfAADAKcIHAABwivABAACcInwAAACnCB8AAMApwgcAAHCK8AEAAJxin48o1PjaOGvNnGFVvb7Oqow99qKu1EzpdSufW24vse1NUrNgjHWO9uqarnaEASJmgv3f3JZvPWmtiVVcKNrRsfaTQcfnVH3POsc/jyZYazzeDmvNxm+uttZUnRptrUkbfNxaM3to8O+7K+4/NsVaU7VgorUm4y8Ddw+PruDOBwAAcIrwAQAAnCJ8AAAApwgfAADAKcIHAABwivABAACcInwAAACnCB8AAMApNhmLMK0FwTfJkqSKKU876ES6uOp6a03FlJcddNJ11o3R3rJvinbVFfbvm43IBhbPCfvmVjdV2jf2SjzjU2vNx3tSrTVnv3Ii6PjIP71rnWOktaJrfqLpIZnng2euttbUFPxX0PGf/WOCdY7fP5RrrRn2l93WGgTHnQ8AAOBUt8PHzp07dc011ygjI0Mej0ebN28OGL/lllvk8XgCjtmzZ4eqXwAAEOG6HT5aWlqUnZ2t0tLSr62ZPXu2jh496j9eeOGFXjUJAACiR7ef+SgoKFBBQUHQGq/Xq7S0tB43BQAAolefPPOxY8cOpaSkaMKECVq8eLE++eSTr61tbW1VU1NTwAEAAKJXyMPH7Nmz9dxzz6msrEyPPPKIysvLVVBQoPb29k7rS0pK5PP5/EdmZmaoWwIAAP1IyF9qe+ONN/o/vvDCCzV58mSdc8452rFjh2bOnPmV+uLiYhUVFfk/b2pqIoAAABDF+vyltmPHjlVycrJqajrf98Dr9SohISHgAAAA0avPNxn76KOP9Mknnyg9Pb2vLzUgTH6oKiTzTHxmcdDxMct2Wefwyb6RVr6mWGs+/k/7pj5d0XKWveb976/u9XXeu3u4tWb8bb2+DCLIZ//3iLVm1Hx7TVecqb+GZJ7+pOPSKdaaF2fa/+3e/LdZQccb58dZ5xhWzwZiLnQ7fJw4cSLgLkZtba2qqqqUlJSkpKQkrVixQvPnz1daWpoOHTqke+65R+PGjVN+fn5IGwcAAJGp2+Fj7969uuKKK/yff/G8xsKFC7V69Wrt379fv/71r3X8+HFlZGRo1qxZeuihh+T1ekPXNQAAiFjdDh8zZsyQMeZrx19//fVeNQQAAKIb7+0CAACcInwAAACnCB8AAMApwgcAAHCK8AEAAJzymGAvXQmDpqYm+Xw+zdBcxXoGh7udfueHNe+HZJ5V4yaGZJ5IEzNhXNDx1956OSTXyc+YEpJ5gIEg/vfJ1pqsM77+DUq/UL7q4qDjSc9XWucwbaetNejcZ6ZNO7RFjY2N1t3KufMBAACcInwAAACnCB8AAMApwgcAAHCK8AEAAJwifAAAAKcIHwAAwCnCBwAAcCo23A2ge14/fqG1ZlXGHntNKJqJQO3VNeFuAYgag4YMsdekp1prPmz0Wmsqq8+21oxftyvoeL/aUXOA484HAABwivABAACcInwAAACnCB8AAMApwgcAAHCK8AEAAJwifAAAAKcIHwAAwCk2GYswXdlArCtiJowLOh6tm3F98PQ0S0WVdY6sV2+z1oxXaP47Af3axLHWkl9s+S9rzc0/+pG1JjEtpkstITJw5wMAADhF+AAAAE4RPgAAgFOEDwAA4BThAwAAOEX4AAAAThE+AACAU4QPAADgFJuMRZhXTw6x1swZdspa89pbLwcdv7jq+i73FEzblpEhmWfw3L9ba+4fv9VaM2dYVa97Oe9n/7TWtPf6KkB4xZ492lpz9EH7T/q3Nt5trRm3ea+15ozPPrPWIHJ0685HSUmJpk2bpvj4eKWkpGjevHmqrq4OqDl16pQKCws1YsQInXnmmZo/f74aGhpC2jQAAIhc3Qof5eXlKiwsVEVFhbZv3662tjbNmjVLLS0t/pq77rpLr7zyijZu3Kjy8nIdOXJE1113XcgbBwAAkalbf3bZtm1bwOfr1q1TSkqKKisrdfnll6uxsVHPPvus1q9fryuvvFKStHbtWp133nmqqKjQxRdfHLrOAQBAROrVA6eNjY2SpKSkJElSZWWl2tralJeX56+ZOHGiRo8erV27dnU6R2trq5qamgIOAAAQvXocPjo6OrR06VJdcsklmjRpkiSpvr5ecXFxSkxMDKhNTU1VfX19p/OUlJTI5/P5j8zMzJ62BAAAIkCPw0dhYaEOHDigDRs29KqB4uJiNTY2+o+6urpezQcAAPq3Hr3UdsmSJdq6dat27typUaNG+c+npaXp9OnTOn78eMDdj4aGBqWlpXU6l9frldfr7UkbAAAgAnXrzocxRkuWLNGmTZv05ptvKisrK2B86tSpGjx4sMrKyvznqqurdfjwYeXm5oamYwAAENG6deejsLBQ69ev15YtWxQfH+9/jsPn82no0KHy+Xz63ve+p6KiIiUlJSkhIUF33HGHcnNzeaVLiDx2x83WmjnPPt3r61RMCb4JWZdNCc00rkxdsdhak1zd+cPTQDQ5uOgsa817U0utNfdnTrHW7IsdZq0xbDIWVboVPlavXi1JmjFjRsD5tWvX6pZbbpEkPfHEExo0aJDmz5+v1tZW5efn65e//GVImgUAAJGvW+HDGGOtGTJkiEpLS1Vaak/EAABg4OGN5QAAgFOEDwAA4BThAwAAOEX4AAAAThE+AACAU4QPAADgVI+2V0f4eH+7x1pz1RXXW2v+umBk0PHEi/5uneP+8VutNXOGnbLWvHpyiLXmoQ+utta0bQn+PUlS8lPBNwhLFhuIIfp1XPYf1prXFzxmrXnkk6nWmqrZnb+1RkA/p45ZaxBduPMBAACcInwAAACnCB8AAMApwgcAAHCK8AEAAJwifAAAAKcIHwAAwCnCBwAAcIpNxqJQe3WNtWbMMnuNzSpN7EJNaPjUlX57/z0B0SBm+PCg4yMfqbXO0dA+1Frz9nXnW2vaG+zXwsDDnQ8AAOAU4QMAADhF+AAAAE4RPgAAgFOEDwAA4BThAwAAOEX4AAAATrHPBwBEmYM/Dr4Hz/tjSq1znP+rJdaas2t2dbkn4Mu48wEAAJwifAAAAKcIHwAAwCnCBwAAcIrwAQAAnCJ8AAAApwgfAADAKcIHAABwik3GACCCmNxsa83/nv/roOPf2LPAOsfZyyq63BPQXd2681FSUqJp06YpPj5eKSkpmjdvnqqrqwNqZsyYIY/HE3DcfvvtIW0aAABErm6Fj/LychUWFqqiokLbt29XW1ubZs2apZaWloC62267TUePHvUfjz76aEibBgAAkatbf3bZtm1bwOfr1q1TSkqKKisrdfnll/vPDxs2TGlpaaHpEAAARJVePXDa2NgoSUpKSgo4//zzzys5OVmTJk1ScXGxTp48+bVztLa2qqmpKeAAAADRq8cPnHZ0dGjp0qW65JJLNGnSJP/573znOxozZowyMjK0f/9+/fjHP1Z1dbV+85vfdDpPSUmJVqxY0dM2AABAhOlx+CgsLNSBAwf09ttvB5xftGiR/+MLL7xQ6enpmjlzpg4dOqRzzjnnK/MUFxerqKjI/3lTU5MyMzN72hYAAOjnehQ+lixZoq1bt2rnzp0aNWpU0NqcnBxJUk1NTafhw+v1yuv19qQNAAAQgboVPowxuuOOO7Rp0ybt2LFDWVlZ1q+pqqqSJKWnp/eoQQAAEF26FT4KCwu1fv16bdmyRfHx8aqvr5ck+Xw+DR06VIcOHdL69et11VVXacSIEdq/f7/uuusuXX755Zo8eXKffAMAMJD87Yf2mjUfzQg6PuxFn30SY7rWENAD3Qofq1evlvT5RmJftnbtWt1yyy2Ki4vTG2+8oZUrV6qlpUWZmZmaP3++7rvvvpA1DAAAIlu3/+wSTGZmpsrLy3vVEAAAiG68sRwAAHCK8AEAAJwifAAAAKcIHwAAwCnCBwAAcIrwAQAAnOrxe7sAANzLuul/rDXtlvEEHQlNM0APcecDAAA4RfgAAABOET4AAIBThA8AAOAU4QMAADhF+AAAAE4RPgAAgFP9bp8PY4wk6TO1SSbMzQAAgC75TG2S/vV7PJh+Fz6am5slSW/rtTB3AgAAuqu5uVk+ny9ojcd0JaI41NHRoSNHjig+Pl4ej0eS1NTUpMzMTNXV1SkhISHMHUYf1rfvscZ9i/Xte6xx34v0NTbGqLm5WRkZGRo0KPhTHf3uzsegQYM0atSoTscSEhIi8j9IpGB9+x5r3LdY377HGve9SF5j2x2PL/DAKQAAcIrwAQAAnIqI8OH1erV8+XJ5vd5wtxKVWN++xxr3Lda377HGfW8grXG/e+AUAABEt4i48wEAAKIH4QMAADhF+AAAAE4RPgAAgFOEDwAA4FS/Dx+lpaU6++yzNWTIEOXk5OhPf/pTuFuKWDt37tQ111yjjIwMeTwebd68OWDcGKNly5YpPT1dQ4cOVV5eng4ePBieZiNQSUmJpk2bpvj4eKWkpGjevHmqrq4OqDl16pQKCws1YsQInXnmmZo/f74aGhrC1HHkWb16tSZPnuzfATI3N1e//e1v/eOsb2g9/PDD8ng8Wrp0qf8ca9w7DzzwgDweT8AxceJE//hAWd9+HT5efPFFFRUVafny5XrnnXeUnZ2t/Px8HTt2LNytRaSWlhZlZ2ertLS00/FHH31Uq1at0po1a7R7926dccYZys/P16lTpxx3GpnKy8tVWFioiooKbd++XW1tbZo1a5ZaWlr8NXfddZdeeeUVbdy4UeXl5Tpy5Iiuu+66MHYdWUaNGqWHH35YlZWV2rt3r6688krNnTtXf/7znyWxvqG0Z88ePfXUU5o8eXLAeda49y644AIdPXrUf7z99tv+sQGzvqYfmz59uiksLPR/3t7ebjIyMkxJSUkYu4oOksymTZv8n3d0dJi0tDTz2GOP+c8dP37ceL1e88ILL4Shw8h37NgxI8mUl5cbYz5fz8GDB5uNGzf6a9577z0jyezatStcbUa84cOHm2eeeYb1DaHm5mZz7rnnmu3bt5tvfvOb5s477zTG8DMcCsuXLzfZ2dmdjg2k9e23dz5Onz6tyspK5eXl+c8NGjRIeXl52rVrVxg7i061tbWqr68PWG+fz6ecnBzWu4caGxslSUlJSZKkyspKtbW1BazxxIkTNXr0aNa4B9rb27Vhwwa1tLQoNzeX9Q2hwsJCzZkzJ2AtJX6GQ+XgwYPKyMjQ2LFjtWDBAh0+fFjSwFrffveutl/4+OOP1d7ertTU1IDzqampev/998PUVfSqr6+XpE7X+4sxdF1HR4eWLl2qSy65RJMmTZL0+RrHxcUpMTExoJY17p53331Xubm5OnXqlM4880xt2rRJ559/vqqqqljfENiwYYPeeecd7dmz5ytj/Az3Xk5OjtatW6cJEybo6NGjWrFihS677DIdOHBgQK1vvw0fQCQrLCzUgQMHAv6Wi9CYMGGCqqqq1NjYqJdfflkLFy5UeXl5uNuKCnV1dbrzzju1fft2DRkyJNztRKWCggL/x5MnT1ZOTo7GjBmjl156SUOHDg1jZ2712z+7JCcnKyYm5itP+TY0NCgtLS1MXUWvL9aU9e69JUuWaOvWrXrrrbc0atQo//m0tDSdPn1ax48fD6hnjbsnLi5O48aN09SpU1VSUqLs7Gz9/Oc/Z31DoLKyUseOHdM3vvENxcbGKjY2VuXl5Vq1apViY2OVmprKGodYYmKixo8fr5qamgH1M9xvw0dcXJymTp2qsrIy/7mOjg6VlZUpNzc3jJ1Fp6ysLKWlpQWsd1NTk3bv3s16d5ExRkuWLNGmTZv05ptvKisrK2B86tSpGjx4cMAaV1dX6/Dhw6xxL3R0dKi1tZX1DYGZM2fq3XffVVVVlf+46KKLtGDBAv/HrHFonThxQocOHVJ6evrA+hkO9xOvwWzYsMF4vV6zbt0685e//MUsWrTIJCYmmvr6+nC3FpGam5vNvn37zL59+4wk8/jjj5t9+/aZDz/80BhjzMMPP2wSExPNli1bzP79+83cuXNNVlaW+fTTT8PceWRYvHix8fl8ZseOHebo0aP+4+TJk/6a22+/3YwePdq8+eabZu/evSY3N9fk5uaGsevIcu+995ry8nJTW1tr9u/fb+69917j8XjM7373O2MM69sXvvxqF2NY49760Y9+ZHbs2GFqa2vNH/7wB5OXl2eSk5PNsWPHjDEDZ337dfgwxpgnn3zSjB492sTFxZnp06ebioqKcLcUsd566y0j6SvHwoULjTGfv9z2/vvvN6mpqcbr9ZqZM2ea6urq8DYdQTpbW0lm7dq1/ppPP/3U/OAHPzDDhw83w4YNM9dee605evRo+JqOMN/97nfNmDFjTFxcnBk5cqSZOXOmP3gYw/r2hX8PH6xx79xwww0mPT3dxMXFmbPOOsvccMMNpqamxj8+UNbXY4wx4bnnAgAABqJ++8wHAACIToQPAADgFOEDAAA4RfgAAABOET4AAIBThA8AAOAU4QMAADhF+AAAAE4RPgAAgFOEDwAA4BThAwAAOPX/AJCijP/jwixfAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(combined_images[0].shape)\n",
    "print(combined_labels[0])\n",
    "plt.imshow(combined_images[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split dataset\n",
    "train_images, train_labels = combined_images[:train_size], combined_labels[:train_size]\n",
    "val_images, val_labels = combined_images[train_size:train_size+val_size], combined_labels[train_size:train_size+val_size]\n",
    "test_images, test_labels = combined_images[train_size+val_size:], combined_labels[train_size+val_size:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_labels = to_categorical(train_labels, num_classes)\n",
    "#val_labels = to_categorical(val_labels, num_classes)\n",
    "#test_labels = to_categorical(test_labels, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train images shape:  (60000, 28, 56, 1)\n",
      "Validation images shape:  (20000, 28, 56, 1)\n",
      "Test images shape:  (20000, 28, 56, 1)\n"
     ]
    }
   ],
   "source": [
    "print(\"Train images shape: \", train_images.shape)\n",
    "print(\"Validation images shape: \", val_images.shape)\n",
    "print(\"Test images shape: \", test_images.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Sequential' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mSequential\u001b[49m([\n\u001b[0;32m      2\u001b[0m     Input(shape\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m28\u001b[39m, \u001b[38;5;241m56\u001b[39m, \u001b[38;5;241m1\u001b[39m)),\n\u001b[0;32m      3\u001b[0m     Flatten(),\n\u001b[0;32m      4\u001b[0m     Dense(\u001b[38;5;241m256\u001b[39m, activation\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrelu\u001b[39m\u001b[38;5;124m'\u001b[39m),\n\u001b[0;32m      5\u001b[0m     Dropout(\u001b[38;5;241m0.2\u001b[39m),\n\u001b[0;32m      6\u001b[0m     Dense(\u001b[38;5;241m256\u001b[39m, activation\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrelu\u001b[39m\u001b[38;5;124m'\u001b[39m),\n\u001b[0;32m      7\u001b[0m     Dense(num_classes, activation\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msoftmax\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      8\u001b[0m ])\n",
      "\u001b[1;31mNameError\u001b[0m: name 'Sequential' is not defined"
     ]
    }
   ],
   "source": [
    "model = Sequential([\n",
    "    Input(shape=(28, 56, 1)),\n",
    "    Flatten(),\n",
    "    Dense(256, activation='relu'),\n",
    "    Dropout(0.2),\n",
    "    Dense(256, activation='relu'),\n",
    "    Dense(num_classes, activation='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=Adam(learning_rate=0.001), loss='mse', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.3133 - loss: 0.0416 - val_accuracy: 0.7246 - val_loss: 0.0204\n",
      "Epoch 2/20\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7441 - loss: 0.0192 - val_accuracy: 0.8123 - val_loss: 0.0143\n",
      "Epoch 3/20\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8222 - loss: 0.0139 - val_accuracy: 0.8454 - val_loss: 0.0119\n",
      "Epoch 4/20\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8566 - loss: 0.0113 - val_accuracy: 0.8602 - val_loss: 0.0108\n",
      "Epoch 5/20\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8776 - loss: 0.0097 - val_accuracy: 0.8796 - val_loss: 0.0095\n",
      "Epoch 6/20\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8931 - loss: 0.0085 - val_accuracy: 0.8849 - val_loss: 0.0089\n",
      "Epoch 7/20\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9022 - loss: 0.0079 - val_accuracy: 0.8932 - val_loss: 0.0085\n",
      "Epoch 8/20\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9133 - loss: 0.0070 - val_accuracy: 0.9003 - val_loss: 0.0079\n",
      "Epoch 9/20\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9206 - loss: 0.0064 - val_accuracy: 0.9019 - val_loss: 0.0078\n",
      "Epoch 10/20\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9283 - loss: 0.0058 - val_accuracy: 0.9090 - val_loss: 0.0073\n",
      "Epoch 11/20\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9335 - loss: 0.0054 - val_accuracy: 0.9089 - val_loss: 0.0072\n",
      "Epoch 12/20\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9389 - loss: 0.0050 - val_accuracy: 0.9112 - val_loss: 0.0072\n",
      "Epoch 13/20\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9393 - loss: 0.0049 - val_accuracy: 0.9136 - val_loss: 0.0070\n",
      "Epoch 14/20\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9425 - loss: 0.0047 - val_accuracy: 0.9153 - val_loss: 0.0068\n",
      "Epoch 15/20\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9474 - loss: 0.0044 - val_accuracy: 0.9198 - val_loss: 0.0064\n",
      "Epoch 16/20\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9484 - loss: 0.0042 - val_accuracy: 0.9204 - val_loss: 0.0065\n",
      "Epoch 17/20\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9502 - loss: 0.0041 - val_accuracy: 0.9221 - val_loss: 0.0063\n",
      "Epoch 18/20\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9541 - loss: 0.0038 - val_accuracy: 0.9229 - val_loss: 0.0063\n",
      "Epoch 19/20\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9550 - loss: 0.0037 - val_accuracy: 0.9254 - val_loss: 0.0061\n",
      "Epoch 20/20\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9563 - loss: 0.0037 - val_accuracy: 0.9275 - val_loss: 0.0060\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x180b1b0bce0>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(\n",
    "    train_images, train_labels,\n",
    "    validation_data=(val_images, val_labels),\n",
    "    epochs=20,\n",
    "    batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9242 - loss: 0.0062\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_mae = model.evaluate(test_images, test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(trial):\n",
    "    # Suggest values for hyperparameters\n",
    "    num_units_layer1 = trial.suggest_int(\"units_layer1\", 256, 512, step=32)\n",
    "    num_units_layer2 = trial.suggest_int(\"units_layer2\", 256, 512, step=32)\n",
    "    dropout_rate = trial.suggest_float(\"dropout_rate\", 0.1, 0.5, step=0.1)\n",
    "    learning_rate = trial.suggest_float(\"learning_rate\", 1e-3, 1e-2, log=True)\n",
    "    batch_size = trial.suggest_categorical(\"batch_size\", [128, 256, 512])\n",
    "\n",
    "    # Build the model\n",
    "    model = Sequential([\n",
    "        Input(shape=(28, 56, 1)),\n",
    "        Flatten(),\n",
    "        Dense(num_units_layer1, activation='relu'),\n",
    "        Dropout(dropout_rate),\n",
    "        Dense(num_units_layer2, activation='relu'),\n",
    "        Dense(num_classes, activation='softmax')\n",
    "    ])\n",
    "    \n",
    "    # Compile the model\n",
    "    model.compile(\n",
    "        optimizer=tf.keras.optimizers.Adam(learning_rate=learning_rate),\n",
    "        loss='categorical_crossentropy',\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "    \n",
    "    # Train the model\n",
    "    history = model.fit(\n",
    "        train_images, train_labels,\n",
    "        validation_data=(val_images, val_labels),\n",
    "        epochs=10,  # Use a small number of epochs for tuning\n",
    "        batch_size=batch_size,\n",
    "        verbose=0  # Suppress output for faster tuning\n",
    "    )\n",
    "    \n",
    "    # Evaluate the model on validation data\n",
    "    val_accuracy = history.history['val_accuracy'][-1]  # Last epoch's validation accuracy\n",
    "    return -val_accuracy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-12-01 20:51:58,111] A new study created in RDB with name: no-name-0de52a26-0012-4b3e-846e-b5e7a5c22566\n",
      "[I 2024-12-01 20:52:08,906] Trial 0 finished with value: -0.900600016117096 and parameters: {'units_layer1': 448, 'units_layer2': 416, 'dropout_rate': 0.5, 'learning_rate': 0.0016921901858626518, 'batch_size': 512}. Best is trial 0 with value: -0.900600016117096.\n",
      "[I 2024-12-01 20:52:34,563] Trial 1 finished with value: -0.9230499863624573 and parameters: {'units_layer1': 384, 'units_layer2': 416, 'dropout_rate': 0.2, 'learning_rate': 0.0014159231001785442, 'batch_size': 128}. Best is trial 1 with value: -0.9230499863624573.\n",
      "[I 2024-12-01 20:52:46,179] Trial 2 finished with value: -0.4345499873161316 and parameters: {'units_layer1': 384, 'units_layer2': 512, 'dropout_rate': 0.2, 'learning_rate': 0.009597445226498219, 'batch_size': 512}. Best is trial 1 with value: -0.9230499863624573.\n",
      "[I 2024-12-01 20:53:10,662] Trial 3 finished with value: -0.826200008392334 and parameters: {'units_layer1': 416, 'units_layer2': 480, 'dropout_rate': 0.4, 'learning_rate': 0.005443707000953646, 'batch_size': 128}. Best is trial 1 with value: -0.9230499863624573.\n",
      "[I 2024-12-01 20:53:24,441] Trial 4 finished with value: -0.9045500159263611 and parameters: {'units_layer1': 480, 'units_layer2': 512, 'dropout_rate': 0.2, 'learning_rate': 0.004319643133703409, 'batch_size': 512}. Best is trial 1 with value: -0.9230499863624573.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters: {'units_layer1': 384, 'units_layer2': 416, 'dropout_rate': 0.2, 'learning_rate': 0.0014159231001785442, 'batch_size': 128}\n",
      "Best validation accuracy: 0.9230\n"
     ]
    }
   ],
   "source": [
    "# Create a study and optimize the objective function\n",
    "storage = \"sqlite:///study.db\"\n",
    "study = optuna.create_study(direction=\"minimize\", storage=storage, load_if_exists=True)\n",
    "study.optimize(objective, n_trials=5)  # Run 50 trials\n",
    "\n",
    "best_params = study.best_params\n",
    "best_accuracy = -study.best_value  # Negate the value to get accuracy\n",
    "print(f\"Best parameters: {best_params}\")\n",
    "print(f\"Best validation accuracy: {best_accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\JZ\\AppData\\Roaming\\Python\\Python312\\site-packages\\keras\\src\\layers\\reshaping\\flatten.py:37: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - accuracy: 0.2987 - loss: 2.1138 - val_accuracy: 0.7412 - val_loss: 0.8504\n",
      "Epoch 2/20\n",
      "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.7101 - loss: 0.9217 - val_accuracy: 0.8142 - val_loss: 0.6098\n",
      "Epoch 3/20\n",
      "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.7957 - loss: 0.6629 - val_accuracy: 0.8582 - val_loss: 0.4803\n",
      "Epoch 4/20\n",
      "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - accuracy: 0.8389 - loss: 0.5249 - val_accuracy: 0.8708 - val_loss: 0.4294\n",
      "Epoch 5/20\n",
      "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.8609 - loss: 0.4507 - val_accuracy: 0.8878 - val_loss: 0.3736\n",
      "Epoch 6/20\n",
      "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - accuracy: 0.8820 - loss: 0.3868 - val_accuracy: 0.8995 - val_loss: 0.3380\n",
      "Epoch 7/20\n",
      "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.8927 - loss: 0.3459 - val_accuracy: 0.9032 - val_loss: 0.3291\n",
      "Epoch 8/20\n",
      "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - accuracy: 0.9040 - loss: 0.3119 - val_accuracy: 0.9123 - val_loss: 0.2959\n",
      "Epoch 9/20\n",
      "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - accuracy: 0.9142 - loss: 0.2757 - val_accuracy: 0.9140 - val_loss: 0.2931\n",
      "Epoch 10/20\n",
      "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.9166 - loss: 0.2677 - val_accuracy: 0.9164 - val_loss: 0.2896\n",
      "Epoch 11/20\n",
      "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - accuracy: 0.9220 - loss: 0.2441 - val_accuracy: 0.9201 - val_loss: 0.2793\n",
      "Epoch 12/20\n",
      "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - accuracy: 0.9291 - loss: 0.2243 - val_accuracy: 0.9237 - val_loss: 0.2629\n",
      "Epoch 13/20\n",
      "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - accuracy: 0.9326 - loss: 0.2099 - val_accuracy: 0.9251 - val_loss: 0.2673\n",
      "Epoch 14/20\n",
      "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - accuracy: 0.9353 - loss: 0.2032 - val_accuracy: 0.9281 - val_loss: 0.2549\n",
      "Epoch 15/20\n",
      "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.9385 - loss: 0.1953 - val_accuracy: 0.9286 - val_loss: 0.2537\n",
      "Epoch 16/20\n",
      "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.9418 - loss: 0.1816 - val_accuracy: 0.9272 - val_loss: 0.2629\n",
      "Epoch 17/20\n",
      "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.9408 - loss: 0.1850 - val_accuracy: 0.9354 - val_loss: 0.2400\n",
      "Epoch 18/20\n",
      "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9448 - loss: 0.1731 - val_accuracy: 0.9305 - val_loss: 0.2552\n",
      "Epoch 19/20\n",
      "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9498 - loss: 0.1623 - val_accuracy: 0.9316 - val_loss: 0.2494\n",
      "Epoch 20/20\n",
      "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9498 - loss: 0.1562 - val_accuracy: 0.9348 - val_loss: 0.2517\n",
      "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9320 - loss: 0.2675\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.28177395462989807, 0.930400013923645]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Build the best model with the optimized parameters\n",
    "best_model = Sequential([\n",
    "    Flatten(input_shape=(28, 56, 1)),\n",
    "    Dense(best_params['units_layer1'], activation='relu'),\n",
    "    Dropout(best_params['dropout_rate']),\n",
    "    Dense(best_params['units_layer2'], activation='relu'),\n",
    "    Dense(num_classes, activation='softmax')\n",
    "])\n",
    "\n",
    "best_model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=best_params['learning_rate']),\n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "# Train the best model on the full training set\n",
    "best_model.fit(\n",
    "    train_images, train_labels,\n",
    "    validation_data=(val_images, val_labels),\n",
    "    epochs=20,\n",
    "    batch_size=best_params['batch_size']\n",
    ")\n",
    "\n",
    "best_model.evaluate(test_images, test_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Flatten the images\n",
    "train_images_flat = train_images.reshape(train_images.shape[0], -1)\n",
    "test_images_flat = test_images.reshape(test_images.shape[0], -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((60000, 1568), (20000, 1568))"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_images_flat.shape, test_images_flat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Random Forest Classifier: 0.7822\n"
     ]
    }
   ],
   "source": [
    "# Random Forest Classifier\n",
    "# This cell takes around 3 mins to run\n",
    "\n",
    "RndFrstClass = RandomForestClassifier(n_estimators=500, max_depth=30)\n",
    "RndFrstClass.fit(train_images_flat, train_labels)\n",
    "RndFrstPred = RndFrstClass.predict(test_images_flat)\n",
    "\n",
    "RFC_model_accuracy = accuracy_score(test_labels, RndFrstPred)\n",
    "print(f\"Accuracy of Random Forest Classifier: {RFC_model_accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Support Vector Classifier: 0.10035\n"
     ]
    }
   ],
   "source": [
    "# Support Vector Classifier\n",
    "\n",
    "svcClass = SVC(gamma=5000)\n",
    "svcClass.fit(train_images_flat, train_labels) \n",
    "svcPred = svcClass.predict(test_images_flat)\n",
    "\n",
    "SVC_model_accuracy = svcClass.score(test_images_flat, test_labels)\n",
    "print(f\"Accuracy of Support Vector Classifier: {SVC_model_accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SVC with RBF kernel\n",
    "# This cell takes around 39 mins to run\n",
    "svcClass = SVC(kernel='rbf')\n",
    "svcClass.fit(train_images_flat, train_labels) \n",
    "svcPred = svcClass.predict(test_images_flat)\n",
    "\n",
    "SVC_model_accuracy = svcClass.score(test_images_flat, test_labels)\n",
    "print(f\"Accuracy of Support Vector Classifier: {SVC_model_accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
