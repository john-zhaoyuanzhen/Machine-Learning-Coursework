{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Coursework"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tensorflow.keras.datasets import mnist #to import our dataset\n",
    "from tensorflow.keras.models import Sequential, Model # imports our type of network\n",
    "from tensorflow.keras.layers import Dense, Flatten, Input, Dropout # imports our layers we want to use\n",
    "\n",
    "from tensorflow.python.keras.losses import categorical_crossentropy #loss function\n",
    "from tensorflow.keras.optimizers import Adam #optimisers\n",
    "from tensorflow.keras.utils import to_categorical #some function for data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "num_classes = 19\n",
    "epochs = 20\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "x_train /= 255\n",
    "x_test /= 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "images = np.concatenate((x_train, x_test), axis=0)\n",
    "labels = np.concatenate((y_train, y_test), axis=0)\n",
    "\n",
    "np.random.seed(73289)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_combined_dataset(iamges, labels, dataset_size=10000):\n",
    "    combined_images = []\n",
    "    combined_labels = []\n",
    "    \n",
    "    for _ in range(dataset_size):\n",
    "        idx1, idx2 = np.random.choice(np.arange(len(images)), 2, replace=True)\n",
    "        img1, img2 = images[idx1], images[idx2]\n",
    "        label1, label2 = labels[idx1], labels[idx2]\n",
    "        \n",
    "        combined_image = np.hstack((img1, img2))\n",
    "        combined_label = label1 + label2\n",
    "        \n",
    "        combined_images.append(combined_image)\n",
    "        combined_labels.append(combined_label)\n",
    "        \n",
    "    combined_images = np.array(combined_images).reshape(-1, 28, 56, 1)\n",
    "    combined_labels = np.array(combined_labels)\n",
    "    \n",
    "    return combined_images, combined_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size:  60000\n",
      "Validation size:  20000\n",
      "Test size:  20000\n"
     ]
    }
   ],
   "source": [
    "dataset_size = 100000\n",
    "train_size = int(0.6 * dataset_size)\n",
    "val_size = int(0.2 * dataset_size)\n",
    "test_size = dataset_size - train_size - val_size\n",
    "\n",
    "print(\"Train size: \", train_size)\n",
    "print(\"Validation size: \", val_size)\n",
    "print(\"Test size: \", test_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_images, combined_labels = create_combined_dataset(images, labels, dataset_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(28, 56, 1)\n",
      "14\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x180ef71a900>"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(combined_images[0].shape)\n",
    "print(combined_labels[0])\n",
    "plt.imshow(combined_images[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split dataset\n",
    "train_images, train_labels = combined_images[:train_size], combined_labels[:train_size]\n",
    "val_images, val_labels = combined_images[train_size:train_size+val_size], combined_labels[train_size:train_size+val_size]\n",
    "test_images, test_labels = combined_images[train_size+val_size:], combined_labels[train_size+val_size:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labels = to_categorical(train_labels, num_classes)\n",
    "val_labels = to_categorical(val_labels, num_classes)\n",
    "test_labels = to_categorical(test_labels, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train images shape:  (60000, 28, 56, 1)\n",
      "Validation images shape:  (20000, 28, 56, 1)\n",
      "Test images shape:  (20000, 28, 56, 1)\n"
     ]
    }
   ],
   "source": [
    "print(\"Train images shape: \", train_images.shape)\n",
    "print(\"Validation images shape: \", val_images.shape)\n",
    "print(\"Test images shape: \", test_images.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Sequential' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mSequential\u001b[49m([\n\u001b[0;32m      2\u001b[0m     Input(shape\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m28\u001b[39m, \u001b[38;5;241m56\u001b[39m, \u001b[38;5;241m1\u001b[39m)),\n\u001b[0;32m      3\u001b[0m     Flatten(),\n\u001b[0;32m      4\u001b[0m     Dense(\u001b[38;5;241m256\u001b[39m, activation\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrelu\u001b[39m\u001b[38;5;124m'\u001b[39m),\n\u001b[0;32m      5\u001b[0m     Dropout(\u001b[38;5;241m0.2\u001b[39m),\n\u001b[0;32m      6\u001b[0m     Dense(\u001b[38;5;241m256\u001b[39m, activation\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrelu\u001b[39m\u001b[38;5;124m'\u001b[39m),\n\u001b[0;32m      7\u001b[0m     Dense(num_classes, activation\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msoftmax\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      8\u001b[0m ])\n",
      "\u001b[1;31mNameError\u001b[0m: name 'Sequential' is not defined"
     ]
    }
   ],
   "source": [
    "model = Sequential([\n",
    "    Input(shape=(28, 56, 1)),\n",
    "    Flatten(),\n",
    "    Dense(256, activation='relu'),\n",
    "    Dropout(0.2),\n",
    "    Dense(256, activation='relu'),\n",
    "    Dense(num_classes, activation='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=Adam(learning_rate=0.001), loss='mse', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.3133 - loss: 0.0416 - val_accuracy: 0.7246 - val_loss: 0.0204\n",
      "Epoch 2/20\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7441 - loss: 0.0192 - val_accuracy: 0.8123 - val_loss: 0.0143\n",
      "Epoch 3/20\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8222 - loss: 0.0139 - val_accuracy: 0.8454 - val_loss: 0.0119\n",
      "Epoch 4/20\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8566 - loss: 0.0113 - val_accuracy: 0.8602 - val_loss: 0.0108\n",
      "Epoch 5/20\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8776 - loss: 0.0097 - val_accuracy: 0.8796 - val_loss: 0.0095\n",
      "Epoch 6/20\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8931 - loss: 0.0085 - val_accuracy: 0.8849 - val_loss: 0.0089\n",
      "Epoch 7/20\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9022 - loss: 0.0079 - val_accuracy: 0.8932 - val_loss: 0.0085\n",
      "Epoch 8/20\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9133 - loss: 0.0070 - val_accuracy: 0.9003 - val_loss: 0.0079\n",
      "Epoch 9/20\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9206 - loss: 0.0064 - val_accuracy: 0.9019 - val_loss: 0.0078\n",
      "Epoch 10/20\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9283 - loss: 0.0058 - val_accuracy: 0.9090 - val_loss: 0.0073\n",
      "Epoch 11/20\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9335 - loss: 0.0054 - val_accuracy: 0.9089 - val_loss: 0.0072\n",
      "Epoch 12/20\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9389 - loss: 0.0050 - val_accuracy: 0.9112 - val_loss: 0.0072\n",
      "Epoch 13/20\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9393 - loss: 0.0049 - val_accuracy: 0.9136 - val_loss: 0.0070\n",
      "Epoch 14/20\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9425 - loss: 0.0047 - val_accuracy: 0.9153 - val_loss: 0.0068\n",
      "Epoch 15/20\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9474 - loss: 0.0044 - val_accuracy: 0.9198 - val_loss: 0.0064\n",
      "Epoch 16/20\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9484 - loss: 0.0042 - val_accuracy: 0.9204 - val_loss: 0.0065\n",
      "Epoch 17/20\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9502 - loss: 0.0041 - val_accuracy: 0.9221 - val_loss: 0.0063\n",
      "Epoch 18/20\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9541 - loss: 0.0038 - val_accuracy: 0.9229 - val_loss: 0.0063\n",
      "Epoch 19/20\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9550 - loss: 0.0037 - val_accuracy: 0.9254 - val_loss: 0.0061\n",
      "Epoch 20/20\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9563 - loss: 0.0037 - val_accuracy: 0.9275 - val_loss: 0.0060\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x180b1b0bce0>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(\n",
    "    train_images, train_labels,\n",
    "    validation_data=(val_images, val_labels),\n",
    "    epochs=20,\n",
    "    batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9242 - loss: 0.0062\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_mae = model.evaluate(test_images, test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(trial):\n",
    "    # Suggest values for hyperparameters\n",
    "    num_units_layer1 = trial.suggest_int(\"units_layer1\", 256, 512, step=32)\n",
    "    num_units_layer2 = trial.suggest_int(\"units_layer2\", 256, 512, step=32)\n",
    "    dropout_rate = trial.suggest_float(\"dropout_rate\", 0.1, 0.5, step=0.1)\n",
    "    learning_rate = trial.suggest_float(\"learning_rate\", 1e-3, 1e-2, log=True)\n",
    "    batch_size = trial.suggest_categorical(\"batch_size\", [128, 256, 512])\n",
    "\n",
    "    # Build the model\n",
    "    model = Sequential([\n",
    "        Input(shape=(28, 56, 1)),\n",
    "        Flatten(),\n",
    "        Dense(num_units_layer1, activation='relu'),\n",
    "        Dropout(dropout_rate),\n",
    "        Dense(num_units_layer2, activation='relu'),\n",
    "        Dense(num_classes, activation='softmax')\n",
    "    ])\n",
    "    \n",
    "    # Compile the model\n",
    "    model.compile(\n",
    "        optimizer=tf.keras.optimizers.Adam(learning_rate=learning_rate),\n",
    "        loss='categorical_crossentropy',\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "    \n",
    "    # Train the model\n",
    "    history = model.fit(\n",
    "        train_images, train_labels,\n",
    "        validation_data=(val_images, val_labels),\n",
    "        epochs=10,  # Use a small number of epochs for tuning\n",
    "        batch_size=batch_size,\n",
    "        verbose=0  # Suppress output for faster tuning\n",
    "    )\n",
    "    \n",
    "    # Evaluate the model on validation data\n",
    "    val_accuracy = history.history['val_accuracy'][-1]  # Last epoch's validation accuracy\n",
    "    return -val_accuracy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-12-01 20:51:58,111] A new study created in RDB with name: no-name-0de52a26-0012-4b3e-846e-b5e7a5c22566\n",
      "[I 2024-12-01 20:52:08,906] Trial 0 finished with value: -0.900600016117096 and parameters: {'units_layer1': 448, 'units_layer2': 416, 'dropout_rate': 0.5, 'learning_rate': 0.0016921901858626518, 'batch_size': 512}. Best is trial 0 with value: -0.900600016117096.\n",
      "[I 2024-12-01 20:52:34,563] Trial 1 finished with value: -0.9230499863624573 and parameters: {'units_layer1': 384, 'units_layer2': 416, 'dropout_rate': 0.2, 'learning_rate': 0.0014159231001785442, 'batch_size': 128}. Best is trial 1 with value: -0.9230499863624573.\n",
      "[I 2024-12-01 20:52:46,179] Trial 2 finished with value: -0.4345499873161316 and parameters: {'units_layer1': 384, 'units_layer2': 512, 'dropout_rate': 0.2, 'learning_rate': 0.009597445226498219, 'batch_size': 512}. Best is trial 1 with value: -0.9230499863624573.\n",
      "[I 2024-12-01 20:53:10,662] Trial 3 finished with value: -0.826200008392334 and parameters: {'units_layer1': 416, 'units_layer2': 480, 'dropout_rate': 0.4, 'learning_rate': 0.005443707000953646, 'batch_size': 128}. Best is trial 1 with value: -0.9230499863624573.\n",
      "[I 2024-12-01 20:53:24,441] Trial 4 finished with value: -0.9045500159263611 and parameters: {'units_layer1': 480, 'units_layer2': 512, 'dropout_rate': 0.2, 'learning_rate': 0.004319643133703409, 'batch_size': 512}. Best is trial 1 with value: -0.9230499863624573.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters: {'units_layer1': 384, 'units_layer2': 416, 'dropout_rate': 0.2, 'learning_rate': 0.0014159231001785442, 'batch_size': 128}\n",
      "Best validation accuracy: 0.9230\n"
     ]
    }
   ],
   "source": [
    "# Create a study and optimize the objective function\n",
    "storage = \"sqlite:///study.db\"\n",
    "study = optuna.create_study(direction=\"minimize\", storage=storage, load_if_exists=True)\n",
    "study.optimize(objective, n_trials=5)  # Run 50 trials\n",
    "\n",
    "best_params = study.best_params\n",
    "best_accuracy = -study.best_value  # Negate the value to get accuracy\n",
    "print(f\"Best parameters: {best_params}\")\n",
    "print(f\"Best validation accuracy: {best_accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\JZ\\AppData\\Roaming\\Python\\Python312\\site-packages\\keras\\src\\layers\\reshaping\\flatten.py:37: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - accuracy: 0.2987 - loss: 2.1138 - val_accuracy: 0.7412 - val_loss: 0.8504\n",
      "Epoch 2/20\n",
      "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.7101 - loss: 0.9217 - val_accuracy: 0.8142 - val_loss: 0.6098\n",
      "Epoch 3/20\n",
      "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.7957 - loss: 0.6629 - val_accuracy: 0.8582 - val_loss: 0.4803\n",
      "Epoch 4/20\n",
      "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - accuracy: 0.8389 - loss: 0.5249 - val_accuracy: 0.8708 - val_loss: 0.4294\n",
      "Epoch 5/20\n",
      "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.8609 - loss: 0.4507 - val_accuracy: 0.8878 - val_loss: 0.3736\n",
      "Epoch 6/20\n",
      "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - accuracy: 0.8820 - loss: 0.3868 - val_accuracy: 0.8995 - val_loss: 0.3380\n",
      "Epoch 7/20\n",
      "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.8927 - loss: 0.3459 - val_accuracy: 0.9032 - val_loss: 0.3291\n",
      "Epoch 8/20\n",
      "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - accuracy: 0.9040 - loss: 0.3119 - val_accuracy: 0.9123 - val_loss: 0.2959\n",
      "Epoch 9/20\n",
      "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - accuracy: 0.9142 - loss: 0.2757 - val_accuracy: 0.9140 - val_loss: 0.2931\n",
      "Epoch 10/20\n",
      "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.9166 - loss: 0.2677 - val_accuracy: 0.9164 - val_loss: 0.2896\n",
      "Epoch 11/20\n",
      "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - accuracy: 0.9220 - loss: 0.2441 - val_accuracy: 0.9201 - val_loss: 0.2793\n",
      "Epoch 12/20\n",
      "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - accuracy: 0.9291 - loss: 0.2243 - val_accuracy: 0.9237 - val_loss: 0.2629\n",
      "Epoch 13/20\n",
      "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - accuracy: 0.9326 - loss: 0.2099 - val_accuracy: 0.9251 - val_loss: 0.2673\n",
      "Epoch 14/20\n",
      "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - accuracy: 0.9353 - loss: 0.2032 - val_accuracy: 0.9281 - val_loss: 0.2549\n",
      "Epoch 15/20\n",
      "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.9385 - loss: 0.1953 - val_accuracy: 0.9286 - val_loss: 0.2537\n",
      "Epoch 16/20\n",
      "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.9418 - loss: 0.1816 - val_accuracy: 0.9272 - val_loss: 0.2629\n",
      "Epoch 17/20\n",
      "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.9408 - loss: 0.1850 - val_accuracy: 0.9354 - val_loss: 0.2400\n",
      "Epoch 18/20\n",
      "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9448 - loss: 0.1731 - val_accuracy: 0.9305 - val_loss: 0.2552\n",
      "Epoch 19/20\n",
      "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9498 - loss: 0.1623 - val_accuracy: 0.9316 - val_loss: 0.2494\n",
      "Epoch 20/20\n",
      "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9498 - loss: 0.1562 - val_accuracy: 0.9348 - val_loss: 0.2517\n",
      "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9320 - loss: 0.2675\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.28177395462989807, 0.930400013923645]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Build the best model with the optimized parameters\n",
    "best_model = Sequential([\n",
    "    Flatten(input_shape=(28, 56, 1)),\n",
    "    Dense(best_params['units_layer1'], activation='relu'),\n",
    "    Dropout(best_params['dropout_rate']),\n",
    "    Dense(best_params['units_layer2'], activation='relu'),\n",
    "    Dense(num_classes, activation='softmax')\n",
    "])\n",
    "\n",
    "best_model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=best_params['learning_rate']),\n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "# Train the best model on the full training set\n",
    "best_model.fit(\n",
    "    train_images, train_labels,\n",
    "    validation_data=(val_images, val_labels),\n",
    "    epochs=20,\n",
    "    batch_size=best_params['batch_size']\n",
    ")\n",
    "\n",
    "best_model.evaluate(test_images, test_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Flatten the images\n",
    "train_images_flat = train_images.reshape(train_images.shape[0], -1)\n",
    "test_images_flat = test_images.reshape(test_images.shape[0], -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((60000, 1568), (20000, 1568))"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_images_flat.shape, test_images_flat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.0476\n"
     ]
    }
   ],
   "source": [
    "# Random Forest Classifier\n",
    "\n",
    "RndFrstClass = RandomForestClassifier(n_estimators=750, max_depth=40, random_state=0, min_samples_split=2, \n",
    "                                      min_samples_leaf=1, max_features=5, oob_score=True)\n",
    "RndFrstClass.fit(train_images_flat, train_labels) \n",
    "RndFrstPred = RndFrstClass.predict(test_images_flat)\n",
    "\n",
    "RFC_model_accuracy = RndFrstClass.score(test_images_flat, test_labels)\n",
    "print(f\"Accuracy of Random Forest Classifier: {RFC_model_accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random Forest Classifier\n",
    "train_labels_flat = np.argmax(train_labels, axis=1)\n",
    "test_labels_flat = np.argmax(test_labels, axis=1)\n",
    "\n",
    "svcClass = SVC(gamma='auto')\n",
    "svcClass.fit(train_images_flat, train_labels_flat) \n",
    "svcPred = svcClass.predict(test_images_flat)\n",
    "\n",
    "SVC_model_accuracy = svcClass.score(test_images_flat, test_labels_flat)\n",
    "print(f\"Accuracy of Support Vector Classifier: {SVC_model_accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
