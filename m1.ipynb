{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Coursework"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tensorflow.keras.datasets import mnist #to import our dataset\n",
    "from tensorflow.keras.models import Sequential, Model # imports our type of network\n",
    "from tensorflow.keras.layers import Dense, Flatten, Input, Dropout # imports our layers we want to use\n",
    "\n",
    "from tensorflow.python.keras.losses import categorical_crossentropy #loss function\n",
    "from tensorflow.keras.optimizers import Adam, SGD #optimisers\n",
    "from tensorflow.keras.utils import to_categorical #some function for data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "num_classes = 19\n",
    "epochs = 20\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "x_train /= 255\n",
    "x_test /= 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "images = np.concatenate((x_train, x_test), axis=0)\n",
    "labels = np.concatenate((y_train, y_test), axis=0)\n",
    "\n",
    "np.random.seed(73289)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_combined_dataset(iamges, labels, dataset_size=10000):\n",
    "    combined_images = []\n",
    "    combined_labels = []\n",
    "    \n",
    "    for _ in range(dataset_size):\n",
    "        idx1, idx2 = np.random.choice(np.arange(len(images)), 2, replace=True)\n",
    "        img1, img2 = images[idx1], images[idx2]\n",
    "        label1, label2 = labels[idx1], labels[idx2]\n",
    "        \n",
    "        combined_image = np.vstack((img1, img2))\n",
    "        combined_label = label1 + label2\n",
    "        \n",
    "        combined_images.append(combined_image)\n",
    "        combined_labels.append(combined_label)\n",
    "        \n",
    "    combined_images = np.array(combined_images).reshape(-1, 56, 28, 1)\n",
    "    combined_labels = np.array(combined_labels)\n",
    "    \n",
    "    return combined_images, combined_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size:  14000\n",
      "Validation size:  2000\n",
      "Test size:  4000\n"
     ]
    }
   ],
   "source": [
    "dataset_size = 20000\n",
    "train_size = int(0.7 * dataset_size)\n",
    "val_size = int(0.1 * dataset_size)\n",
    "test_size = dataset_size - train_size - val_size\n",
    "\n",
    "print(\"Train size: \", train_size)\n",
    "print(\"Validation size: \", val_size)\n",
    "print(\"Test size: \", test_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_images, combined_labels = create_combined_dataset(images, labels, dataset_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(56, 28, 1)\n",
      "11\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x19f02943ec0>"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(combined_images[0].shape)\n",
    "print(combined_labels[0])\n",
    "plt.imshow(combined_images[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split dataset\n",
    "train_images, train_labels = combined_images[:train_size], combined_labels[:train_size]\n",
    "val_images, val_labels = combined_images[train_size:train_size+val_size], combined_labels[train_size:train_size+val_size]\n",
    "test_images, test_labels = combined_images[train_size+val_size:], combined_labels[train_size+val_size:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train images shape:  (14000, 56, 28, 1)\n",
      "Train labels shape:  (14000,)\n",
      "Validation images shape:  (2000, 56, 28, 1)\n",
      "Validation labels shape:  (2000,)\n",
      "Test images shape:  (4000, 56, 28, 1)\n",
      "Test labels shape:  (4000,)\n"
     ]
    }
   ],
   "source": [
    "print(\"Train images shape: \", train_images.shape)\n",
    "print(\"Train labels shape: \", train_labels.shape)\n",
    "print(\"Validation images shape: \", val_images.shape)\n",
    "print(\"Validation labels shape: \", val_labels.shape)\n",
    "print(\"Test images shape: \", test_images.shape)\n",
    "print(\"Test labels shape: \", test_labels.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "ename": "ResourceExhaustedError",
     "evalue": "{{function_node __wrapped__StatelessRandomUniformV2_device_/job:localhost/replica:0/task:0/device:CPU:0}} OOM when allocating tensor with shape[21952000,512] and type float on /job:localhost/replica:0/task:0/device:CPU:0 by allocator mklcpu [Op:StatelessRandomUniformV2] name: ",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[79], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mSequential\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\n\u001b[0;32m      2\u001b[0m \u001b[43m    \u001b[49m\u001b[43mInput\u001b[49m\u001b[43m(\u001b[49m\u001b[43mshape\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain_images\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[43mFlatten\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[43mDense\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m512\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mactivation\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mrelu\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[43mDropout\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.01\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[43mDense\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m256\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mactivation\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mrelu\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      7\u001b[0m \u001b[43m    \u001b[49m\u001b[43mDropout\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.01\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      8\u001b[0m \u001b[43m    \u001b[49m\u001b[43mDense\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnum_classes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mactivation\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43msoftmax\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      9\u001b[0m \u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\keras\\src\\models\\sequential.py:76\u001b[0m, in \u001b[0;36mSequential.__init__\u001b[1;34m(self, layers, trainable, name)\u001b[0m\n\u001b[0;32m     74\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m layer \u001b[38;5;129;01min\u001b[39;00m layers:\n\u001b[0;32m     75\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39madd(layer, rebuild\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m---> 76\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_maybe_rebuild\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\keras\\src\\models\\sequential.py:141\u001b[0m, in \u001b[0;36mSequential._maybe_rebuild\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    139\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_layers[\u001b[38;5;241m0\u001b[39m], InputLayer) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_layers) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m    140\u001b[0m     input_shape \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_layers[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mbatch_shape\n\u001b[1;32m--> 141\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbuild\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_shape\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    142\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_layers[\u001b[38;5;241m0\u001b[39m], \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minput_shape\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_layers) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m    143\u001b[0m     \u001b[38;5;66;03m# We can build the Sequential model if the first layer has the\u001b[39;00m\n\u001b[0;32m    144\u001b[0m     \u001b[38;5;66;03m# `input_shape` property. This is most commonly found in Functional\u001b[39;00m\n\u001b[0;32m    145\u001b[0m     \u001b[38;5;66;03m# model.\u001b[39;00m\n\u001b[0;32m    146\u001b[0m     input_shape \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_layers[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39minput_shape\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\keras\\src\\layers\\layer.py:226\u001b[0m, in \u001b[0;36mLayer.__new__.<locals>.build_wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    224\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m obj\u001b[38;5;241m.\u001b[39m_open_name_scope():\n\u001b[0;32m    225\u001b[0m     obj\u001b[38;5;241m.\u001b[39m_path \u001b[38;5;241m=\u001b[39m current_path()\n\u001b[1;32m--> 226\u001b[0m     \u001b[43moriginal_build_method\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    227\u001b[0m \u001b[38;5;66;03m# Record build config.\u001b[39;00m\n\u001b[0;32m    228\u001b[0m signature \u001b[38;5;241m=\u001b[39m inspect\u001b[38;5;241m.\u001b[39msignature(original_build_method)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\keras\\src\\models\\sequential.py:187\u001b[0m, in \u001b[0;36mSequential.build\u001b[1;34m(self, input_shape)\u001b[0m\n\u001b[0;32m    185\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m layer \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_layers[\u001b[38;5;241m1\u001b[39m:]:\n\u001b[0;32m    186\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 187\u001b[0m         x \u001b[38;5;241m=\u001b[39m \u001b[43mlayer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    188\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m:\n\u001b[0;32m    189\u001b[0m         \u001b[38;5;66;03m# Can happen if shape inference is not implemented.\u001b[39;00m\n\u001b[0;32m    190\u001b[0m         \u001b[38;5;66;03m# TODO: consider reverting inbound nodes on layers processed.\u001b[39;00m\n\u001b[0;32m    191\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\keras\\src\\utils\\traceback_utils.py:122\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m    120\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m    121\u001b[0m     \u001b[38;5;66;03m# `keras.config.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m--> 122\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    123\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    124\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\keras\\src\\backend\\tensorflow\\random.py:34\u001b[0m, in \u001b[0;36muniform\u001b[1;34m(shape, minval, maxval, dtype, seed)\u001b[0m\n\u001b[0;32m     32\u001b[0m dtype \u001b[38;5;241m=\u001b[39m dtype \u001b[38;5;129;01mor\u001b[39;00m floatx()\n\u001b[0;32m     33\u001b[0m seed \u001b[38;5;241m=\u001b[39m _cast_seed(draw_seed(seed))\n\u001b[1;32m---> 34\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrandom\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstateless_uniform\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     35\u001b[0m \u001b[43m    \u001b[49m\u001b[43mshape\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mshape\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     36\u001b[0m \u001b[43m    \u001b[49m\u001b[43mminval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcast\u001b[49m\u001b[43m(\u001b[49m\u001b[43mminval\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     37\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmaxval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcast\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmaxval\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     38\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     39\u001b[0m \u001b[43m    \u001b[49m\u001b[43mseed\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mseed\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     40\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mResourceExhaustedError\u001b[0m: {{function_node __wrapped__StatelessRandomUniformV2_device_/job:localhost/replica:0/task:0/device:CPU:0}} OOM when allocating tensor with shape[21952000,512] and type float on /job:localhost/replica:0/task:0/device:CPU:0 by allocator mklcpu [Op:StatelessRandomUniformV2] name: "
     ]
    }
   ],
   "source": [
    "model = Sequential([\n",
    "    Input(shape=train_images.shape),\n",
    "    Flatten(),\n",
    "    Dense(512, activation='relu'),\n",
    "    Dropout(rate=0.01),\n",
    "    Dense(256, activation='relu'),\n",
    "    Dropout(rate=0.01),\n",
    "    Dense(num_classes, activation='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=Adam(learning_rate=0.1), loss='mean_squared_error', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "ename": "InvalidArgumentError",
     "evalue": "Graph execution error:\n\nDetected at node compile_loss/mean_squared_error/sub defined at (most recent call last):\n  File \"<frozen runpy>\", line 198, in _run_module_as_main\n\n  File \"<frozen runpy>\", line 88, in _run_code\n\n  File \"C:\\Users\\JZ\\AppData\\Roaming\\Python\\Python312\\site-packages\\ipykernel_launcher.py\", line 18, in <module>\n\n  File \"C:\\Users\\JZ\\AppData\\Roaming\\Python\\Python312\\site-packages\\traitlets\\config\\application.py\", line 1075, in launch_instance\n\n  File \"C:\\Users\\JZ\\AppData\\Roaming\\Python\\Python312\\site-packages\\ipykernel\\kernelapp.py\", line 739, in start\n\n  File \"C:\\Users\\JZ\\AppData\\Roaming\\Python\\Python312\\site-packages\\tornado\\platform\\asyncio.py\", line 205, in start\n\n  File \"c:\\Python312\\Lib\\asyncio\\base_events.py\", line 641, in run_forever\n\n  File \"c:\\Python312\\Lib\\asyncio\\base_events.py\", line 1986, in _run_once\n\n  File \"c:\\Python312\\Lib\\asyncio\\events.py\", line 88, in _run\n\n  File \"C:\\Users\\JZ\\AppData\\Roaming\\Python\\Python312\\site-packages\\ipykernel\\kernelbase.py\", line 545, in dispatch_queue\n\n  File \"C:\\Users\\JZ\\AppData\\Roaming\\Python\\Python312\\site-packages\\ipykernel\\kernelbase.py\", line 534, in process_one\n\n  File \"C:\\Users\\JZ\\AppData\\Roaming\\Python\\Python312\\site-packages\\ipykernel\\kernelbase.py\", line 437, in dispatch_shell\n\n  File \"C:\\Users\\JZ\\AppData\\Roaming\\Python\\Python312\\site-packages\\ipykernel\\ipkernel.py\", line 362, in execute_request\n\n  File \"C:\\Users\\JZ\\AppData\\Roaming\\Python\\Python312\\site-packages\\ipykernel\\kernelbase.py\", line 778, in execute_request\n\n  File \"C:\\Users\\JZ\\AppData\\Roaming\\Python\\Python312\\site-packages\\ipykernel\\ipkernel.py\", line 449, in do_execute\n\n  File \"C:\\Users\\JZ\\AppData\\Roaming\\Python\\Python312\\site-packages\\ipykernel\\zmqshell.py\", line 549, in run_cell\n\n  File \"C:\\Users\\JZ\\AppData\\Roaming\\Python\\Python312\\site-packages\\IPython\\core\\interactiveshell.py\", line 3075, in run_cell\n\n  File \"C:\\Users\\JZ\\AppData\\Roaming\\Python\\Python312\\site-packages\\IPython\\core\\interactiveshell.py\", line 3130, in _run_cell\n\n  File \"C:\\Users\\JZ\\AppData\\Roaming\\Python\\Python312\\site-packages\\IPython\\core\\async_helpers.py\", line 128, in _pseudo_sync_runner\n\n  File \"C:\\Users\\JZ\\AppData\\Roaming\\Python\\Python312\\site-packages\\IPython\\core\\interactiveshell.py\", line 3334, in run_cell_async\n\n  File \"C:\\Users\\JZ\\AppData\\Roaming\\Python\\Python312\\site-packages\\IPython\\core\\interactiveshell.py\", line 3517, in run_ast_nodes\n\n  File \"C:\\Users\\JZ\\AppData\\Roaming\\Python\\Python312\\site-packages\\IPython\\core\\interactiveshell.py\", line 3577, in run_code\n\n  File \"C:\\Users\\JZ\\AppData\\Local\\Temp\\ipykernel_2996\\3847836219.py\", line 1, in <module>\n\n  File \"C:\\Users\\JZ\\AppData\\Roaming\\Python\\Python312\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 117, in error_handler\n\n  File \"C:\\Users\\JZ\\AppData\\Roaming\\Python\\Python312\\site-packages\\keras\\src\\backend\\tensorflow\\trainer.py\", line 320, in fit\n\n  File \"C:\\Users\\JZ\\AppData\\Roaming\\Python\\Python312\\site-packages\\keras\\src\\backend\\tensorflow\\trainer.py\", line 121, in one_step_on_iterator\n\n  File \"C:\\Users\\JZ\\AppData\\Roaming\\Python\\Python312\\site-packages\\keras\\src\\backend\\tensorflow\\trainer.py\", line 108, in one_step_on_data\n\n  File \"C:\\Users\\JZ\\AppData\\Roaming\\Python\\Python312\\site-packages\\keras\\src\\backend\\tensorflow\\trainer.py\", line 54, in train_step\n\n  File \"C:\\Users\\JZ\\AppData\\Roaming\\Python\\Python312\\site-packages\\keras\\src\\trainers\\trainer.py\", line 398, in _compute_loss\n\n  File \"C:\\Users\\JZ\\AppData\\Roaming\\Python\\Python312\\site-packages\\keras\\src\\trainers\\trainer.py\", line 366, in compute_loss\n\n  File \"C:\\Users\\JZ\\AppData\\Roaming\\Python\\Python312\\site-packages\\keras\\src\\trainers\\compile_utils.py\", line 618, in __call__\n\n  File \"C:\\Users\\JZ\\AppData\\Roaming\\Python\\Python312\\site-packages\\keras\\src\\trainers\\compile_utils.py\", line 659, in call\n\n  File \"C:\\Users\\JZ\\AppData\\Roaming\\Python\\Python312\\site-packages\\keras\\src\\losses\\loss.py\", line 60, in __call__\n\n  File \"C:\\Users\\JZ\\AppData\\Roaming\\Python\\Python312\\site-packages\\keras\\src\\losses\\losses.py\", line 27, in call\n\n  File \"C:\\Users\\JZ\\AppData\\Roaming\\Python\\Python312\\site-packages\\keras\\src\\losses\\losses.py\", line 1303, in mean_squared_error\n\nIncompatible shapes: [128] vs. [128,19]\n\t [[{{node compile_loss/mean_squared_error/sub}}]] [Op:__inference_one_step_on_iterator_98591]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[76], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m      2\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtest_images\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_labels\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mval_images\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_labels\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m50\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m128\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\keras\\src\\utils\\traceback_utils.py:122\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m    120\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m    121\u001b[0m     \u001b[38;5;66;03m# `keras.config.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m--> 122\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    123\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    124\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\tensorflow\\python\\eager\\execute.py:53\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     51\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     52\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 53\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m pywrap_tfe\u001b[38;5;241m.\u001b[39mTFE_Py_Execute(ctx\u001b[38;5;241m.\u001b[39m_handle, device_name, op_name,\n\u001b[0;32m     54\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[0;32m     55\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     56\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mInvalidArgumentError\u001b[0m: Graph execution error:\n\nDetected at node compile_loss/mean_squared_error/sub defined at (most recent call last):\n  File \"<frozen runpy>\", line 198, in _run_module_as_main\n\n  File \"<frozen runpy>\", line 88, in _run_code\n\n  File \"C:\\Users\\JZ\\AppData\\Roaming\\Python\\Python312\\site-packages\\ipykernel_launcher.py\", line 18, in <module>\n\n  File \"C:\\Users\\JZ\\AppData\\Roaming\\Python\\Python312\\site-packages\\traitlets\\config\\application.py\", line 1075, in launch_instance\n\n  File \"C:\\Users\\JZ\\AppData\\Roaming\\Python\\Python312\\site-packages\\ipykernel\\kernelapp.py\", line 739, in start\n\n  File \"C:\\Users\\JZ\\AppData\\Roaming\\Python\\Python312\\site-packages\\tornado\\platform\\asyncio.py\", line 205, in start\n\n  File \"c:\\Python312\\Lib\\asyncio\\base_events.py\", line 641, in run_forever\n\n  File \"c:\\Python312\\Lib\\asyncio\\base_events.py\", line 1986, in _run_once\n\n  File \"c:\\Python312\\Lib\\asyncio\\events.py\", line 88, in _run\n\n  File \"C:\\Users\\JZ\\AppData\\Roaming\\Python\\Python312\\site-packages\\ipykernel\\kernelbase.py\", line 545, in dispatch_queue\n\n  File \"C:\\Users\\JZ\\AppData\\Roaming\\Python\\Python312\\site-packages\\ipykernel\\kernelbase.py\", line 534, in process_one\n\n  File \"C:\\Users\\JZ\\AppData\\Roaming\\Python\\Python312\\site-packages\\ipykernel\\kernelbase.py\", line 437, in dispatch_shell\n\n  File \"C:\\Users\\JZ\\AppData\\Roaming\\Python\\Python312\\site-packages\\ipykernel\\ipkernel.py\", line 362, in execute_request\n\n  File \"C:\\Users\\JZ\\AppData\\Roaming\\Python\\Python312\\site-packages\\ipykernel\\kernelbase.py\", line 778, in execute_request\n\n  File \"C:\\Users\\JZ\\AppData\\Roaming\\Python\\Python312\\site-packages\\ipykernel\\ipkernel.py\", line 449, in do_execute\n\n  File \"C:\\Users\\JZ\\AppData\\Roaming\\Python\\Python312\\site-packages\\ipykernel\\zmqshell.py\", line 549, in run_cell\n\n  File \"C:\\Users\\JZ\\AppData\\Roaming\\Python\\Python312\\site-packages\\IPython\\core\\interactiveshell.py\", line 3075, in run_cell\n\n  File \"C:\\Users\\JZ\\AppData\\Roaming\\Python\\Python312\\site-packages\\IPython\\core\\interactiveshell.py\", line 3130, in _run_cell\n\n  File \"C:\\Users\\JZ\\AppData\\Roaming\\Python\\Python312\\site-packages\\IPython\\core\\async_helpers.py\", line 128, in _pseudo_sync_runner\n\n  File \"C:\\Users\\JZ\\AppData\\Roaming\\Python\\Python312\\site-packages\\IPython\\core\\interactiveshell.py\", line 3334, in run_cell_async\n\n  File \"C:\\Users\\JZ\\AppData\\Roaming\\Python\\Python312\\site-packages\\IPython\\core\\interactiveshell.py\", line 3517, in run_ast_nodes\n\n  File \"C:\\Users\\JZ\\AppData\\Roaming\\Python\\Python312\\site-packages\\IPython\\core\\interactiveshell.py\", line 3577, in run_code\n\n  File \"C:\\Users\\JZ\\AppData\\Local\\Temp\\ipykernel_2996\\3847836219.py\", line 1, in <module>\n\n  File \"C:\\Users\\JZ\\AppData\\Roaming\\Python\\Python312\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 117, in error_handler\n\n  File \"C:\\Users\\JZ\\AppData\\Roaming\\Python\\Python312\\site-packages\\keras\\src\\backend\\tensorflow\\trainer.py\", line 320, in fit\n\n  File \"C:\\Users\\JZ\\AppData\\Roaming\\Python\\Python312\\site-packages\\keras\\src\\backend\\tensorflow\\trainer.py\", line 121, in one_step_on_iterator\n\n  File \"C:\\Users\\JZ\\AppData\\Roaming\\Python\\Python312\\site-packages\\keras\\src\\backend\\tensorflow\\trainer.py\", line 108, in one_step_on_data\n\n  File \"C:\\Users\\JZ\\AppData\\Roaming\\Python\\Python312\\site-packages\\keras\\src\\backend\\tensorflow\\trainer.py\", line 54, in train_step\n\n  File \"C:\\Users\\JZ\\AppData\\Roaming\\Python\\Python312\\site-packages\\keras\\src\\trainers\\trainer.py\", line 398, in _compute_loss\n\n  File \"C:\\Users\\JZ\\AppData\\Roaming\\Python\\Python312\\site-packages\\keras\\src\\trainers\\trainer.py\", line 366, in compute_loss\n\n  File \"C:\\Users\\JZ\\AppData\\Roaming\\Python\\Python312\\site-packages\\keras\\src\\trainers\\compile_utils.py\", line 618, in __call__\n\n  File \"C:\\Users\\JZ\\AppData\\Roaming\\Python\\Python312\\site-packages\\keras\\src\\trainers\\compile_utils.py\", line 659, in call\n\n  File \"C:\\Users\\JZ\\AppData\\Roaming\\Python\\Python312\\site-packages\\keras\\src\\losses\\loss.py\", line 60, in __call__\n\n  File \"C:\\Users\\JZ\\AppData\\Roaming\\Python\\Python312\\site-packages\\keras\\src\\losses\\losses.py\", line 27, in call\n\n  File \"C:\\Users\\JZ\\AppData\\Roaming\\Python\\Python312\\site-packages\\keras\\src\\losses\\losses.py\", line 1303, in mean_squared_error\n\nIncompatible shapes: [128] vs. [128,19]\n\t [[{{node compile_loss/mean_squared_error/sub}}]] [Op:__inference_one_step_on_iterator_98591]"
     ]
    }
   ],
   "source": [
    "model.fit(\n",
    "    test_images, test_labels,\n",
    "    validation_data=(val_images, val_labels),\n",
    "    epochs=50,\n",
    "    batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8089 - loss: 0.1777\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_mae = model.evaluate(test_images, test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "import optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(trial):\n",
    "    # Suggest values for hyperparameters\n",
    "    num_units_layer1 = trial.suggest_int(\"units_layer1\", 128, 256, step=32)\n",
    "    num_units_layer2 = trial.suggest_int(\"units_layer2\", 64, 128, step=16)\n",
    "    dropout_rate = trial.suggest_float(\"dropout_rate\", 0.1, 0.5, step=0.1)\n",
    "    learning_rate = trial.suggest_float(\"learning_rate\", 1e-3, 1e-1, log=True)\n",
    "    batch_size = trial.suggest_categorical(\"batch_size\", [8, 16, 32, 64])\n",
    "\n",
    "    # Build the model\n",
    "    model = Sequential([\n",
    "        Input(shape=(56, 28, 1)),\n",
    "        Flatten(),\n",
    "        Dense(num_units_layer1, activation='relu'),\n",
    "        Dropout(dropout_rate),\n",
    "        Dense(num_units_layer2, activation='relu'),\n",
    "        Dense(1)  # Output layer for regression\n",
    "    ])\n",
    "    \n",
    "    # Compile the model\n",
    "    model.compile(\n",
    "        optimizer=tf.keras.optimizers.Adam(learning_rate=learning_rate),\n",
    "        loss='categorical_crossentropy',\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "    \n",
    "    # Train the model\n",
    "    history = model.fit(\n",
    "        train_images, train_labels,\n",
    "        validation_data=(val_images, val_labels),\n",
    "        epochs=10,  # Use a small number of epochs for tuning\n",
    "        batch_size=batch_size,\n",
    "        verbose=0  # Suppress output for faster tuning\n",
    "    )\n",
    "    \n",
    "    # Evaluate the model on validation data\n",
    "    val_accuracy = history.history['val_accuracy'][-1]  # Last epoch's validation accuracy\n",
    "    return -val_accuracy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-11-27 21:45:06,757] A new study created in memory with name: no-name-507d0cf6-71a9-4b24-9068-0e17f2b82f5c\n",
      "C:\\Users\\JZ\\AppData\\Roaming\\Python\\Python312\\site-packages\\keras\\src\\losses\\losses.py:27: SyntaxWarning: In loss categorical_crossentropy, expected y_pred.shape to be (batch_size, num_classes) with num_classes > 1. Received: y_pred.shape=(16, 1). Consider using 'binary_crossentropy' if you only have 2 classes.\n",
      "  return self.fn(y_true, y_pred, **self._fn_kwargs)\n",
      "[I 2024-11-27 21:45:28,804] Trial 0 finished with value: -0.008500000461935997 and parameters: {'units_layer1': 160, 'units_layer2': 80, 'dropout_rate': 0.2, 'learning_rate': 0.0141971229571766, 'batch_size': 16}. Best is trial 0 with value: -0.008500000461935997.\n",
      "C:\\Users\\JZ\\AppData\\Roaming\\Python\\Python312\\site-packages\\keras\\src\\losses\\losses.py:27: SyntaxWarning: In loss categorical_crossentropy, expected y_pred.shape to be (batch_size, num_classes) with num_classes > 1. Received: y_pred.shape=(None, 1). Consider using 'binary_crossentropy' if you only have 2 classes.\n",
      "  return self.fn(y_true, y_pred, **self._fn_kwargs)\n",
      "[I 2024-11-27 21:45:37,030] Trial 1 finished with value: -0.007000000216066837 and parameters: {'units_layer1': 160, 'units_layer2': 64, 'dropout_rate': 0.4, 'learning_rate': 0.0016461378389931933, 'batch_size': 64}. Best is trial 0 with value: -0.008500000461935997.\n",
      "[I 2024-11-27 21:46:05,747] Trial 2 finished with value: -0.006500000134110451 and parameters: {'units_layer1': 256, 'units_layer2': 80, 'dropout_rate': 0.30000000000000004, 'learning_rate': 0.0031906036244720563, 'batch_size': 16}. Best is trial 0 with value: -0.008500000461935997.\n",
      "[I 2024-11-27 21:46:27,259] Trial 3 finished with value: -0.012500000186264515 and parameters: {'units_layer1': 192, 'units_layer2': 112, 'dropout_rate': 0.1, 'learning_rate': 0.03860836708658817, 'batch_size': 16}. Best is trial 3 with value: -0.012500000186264515.\n",
      "[I 2024-11-27 21:46:52,677] Trial 4 finished with value: -0.008500000461935997 and parameters: {'units_layer1': 160, 'units_layer2': 128, 'dropout_rate': 0.1, 'learning_rate': 0.0013553335895287856, 'batch_size': 16}. Best is trial 3 with value: -0.012500000186264515.\n",
      "[I 2024-11-27 21:47:14,201] Trial 5 finished with value: -0.011500000022351742 and parameters: {'units_layer1': 160, 'units_layer2': 80, 'dropout_rate': 0.5, 'learning_rate': 0.011086645877582417, 'batch_size': 16}. Best is trial 3 with value: -0.012500000186264515.\n",
      "[I 2024-11-27 21:47:22,217] Trial 6 finished with value: -0.012500000186264515 and parameters: {'units_layer1': 256, 'units_layer2': 80, 'dropout_rate': 0.5, 'learning_rate': 0.008654595078844052, 'batch_size': 64}. Best is trial 3 with value: -0.012500000186264515.\n",
      "[I 2024-11-27 21:47:28,958] Trial 7 finished with value: -0.008500000461935997 and parameters: {'units_layer1': 160, 'units_layer2': 64, 'dropout_rate': 0.30000000000000004, 'learning_rate': 0.0014622724276580523, 'batch_size': 64}. Best is trial 3 with value: -0.012500000186264515.\n",
      "[I 2024-11-27 21:47:34,792] Trial 8 finished with value: -0.008500000461935997 and parameters: {'units_layer1': 128, 'units_layer2': 64, 'dropout_rate': 0.30000000000000004, 'learning_rate': 0.007079738735755291, 'batch_size': 64}. Best is trial 3 with value: -0.012500000186264515.\n",
      "[I 2024-11-27 21:47:44,573] Trial 9 finished with value: -0.007499999832361937 and parameters: {'units_layer1': 128, 'units_layer2': 80, 'dropout_rate': 0.2, 'learning_rate': 0.07682473639417729, 'batch_size': 32}. Best is trial 3 with value: -0.012500000186264515.\n",
      "[I 2024-11-27 21:47:57,630] Trial 10 finished with value: -0.008999999612569809 and parameters: {'units_layer1': 224, 'units_layer2': 128, 'dropout_rate': 0.1, 'learning_rate': 0.05749767682623507, 'batch_size': 32}. Best is trial 3 with value: -0.012500000186264515.\n",
      "[I 2024-11-27 21:48:05,033] Trial 11 finished with value: -0.00800000037997961 and parameters: {'units_layer1': 224, 'units_layer2': 112, 'dropout_rate': 0.5, 'learning_rate': 0.025848214657686726, 'batch_size': 64}. Best is trial 3 with value: -0.012500000186264515.\n",
      "[I 2024-11-27 21:48:12,863] Trial 12 finished with value: -0.007499999832361937 and parameters: {'units_layer1': 224, 'units_layer2': 112, 'dropout_rate': 0.4, 'learning_rate': 0.032761491108931846, 'batch_size': 64}. Best is trial 3 with value: -0.012500000186264515.\n",
      "[I 2024-11-27 21:48:36,235] Trial 13 finished with value: -0.008500000461935997 and parameters: {'units_layer1': 256, 'units_layer2': 96, 'dropout_rate': 0.4, 'learning_rate': 0.005686121663355025, 'batch_size': 16}. Best is trial 3 with value: -0.012500000186264515.\n",
      "[I 2024-11-27 21:48:48,324] Trial 14 finished with value: -0.008500000461935997 and parameters: {'units_layer1': 192, 'units_layer2': 96, 'dropout_rate': 0.2, 'learning_rate': 0.02069961610935092, 'batch_size': 32}. Best is trial 3 with value: -0.012500000186264515.\n",
      "[I 2024-11-27 21:49:09,496] Trial 15 finished with value: -0.008999999612569809 and parameters: {'units_layer1': 192, 'units_layer2': 112, 'dropout_rate': 0.1, 'learning_rate': 0.044165454722752996, 'batch_size': 16}. Best is trial 3 with value: -0.012500000186264515.\n",
      "[I 2024-11-27 21:49:16,425] Trial 16 finished with value: -0.008500000461935997 and parameters: {'units_layer1': 224, 'units_layer2': 96, 'dropout_rate': 0.5, 'learning_rate': 0.005023768498606571, 'batch_size': 64}. Best is trial 3 with value: -0.012500000186264515.\n",
      "[I 2024-11-27 21:49:37,473] Trial 17 finished with value: -0.008500000461935997 and parameters: {'units_layer1': 256, 'units_layer2': 96, 'dropout_rate': 0.2, 'learning_rate': 0.015023331787670437, 'batch_size': 16}. Best is trial 3 with value: -0.012500000186264515.\n",
      "[I 2024-11-27 21:49:43,840] Trial 18 finished with value: -0.008500000461935997 and parameters: {'units_layer1': 192, 'units_layer2': 112, 'dropout_rate': 0.4, 'learning_rate': 0.09347519615209625, 'batch_size': 64}. Best is trial 3 with value: -0.012500000186264515.\n",
      "[I 2024-11-27 21:49:55,349] Trial 19 finished with value: -0.008500000461935997 and parameters: {'units_layer1': 224, 'units_layer2': 128, 'dropout_rate': 0.5, 'learning_rate': 0.003332722205247602, 'batch_size': 32}. Best is trial 3 with value: -0.012500000186264515.\n",
      "[I 2024-11-27 21:50:01,772] Trial 20 finished with value: -0.008500000461935997 and parameters: {'units_layer1': 192, 'units_layer2': 112, 'dropout_rate': 0.1, 'learning_rate': 0.007727087649654362, 'batch_size': 64}. Best is trial 3 with value: -0.012500000186264515.\n",
      "[I 2024-11-27 21:50:19,400] Trial 21 finished with value: -0.008500000461935997 and parameters: {'units_layer1': 160, 'units_layer2': 80, 'dropout_rate': 0.5, 'learning_rate': 0.012866254102437311, 'batch_size': 16}. Best is trial 3 with value: -0.012500000186264515.\n",
      "[I 2024-11-27 21:50:37,879] Trial 22 finished with value: -0.008500000461935997 and parameters: {'units_layer1': 192, 'units_layer2': 80, 'dropout_rate': 0.5, 'learning_rate': 0.010839578445065055, 'batch_size': 16}. Best is trial 3 with value: -0.012500000186264515.\n",
      "[I 2024-11-27 21:50:51,078] Trial 23 finished with value: -0.008500000461935997 and parameters: {'units_layer1': 128, 'units_layer2': 80, 'dropout_rate': 0.4, 'learning_rate': 0.01975866732326502, 'batch_size': 16}. Best is trial 3 with value: -0.012500000186264515.\n",
      "[I 2024-11-27 21:51:09,476] Trial 24 finished with value: -0.01549999974668026 and parameters: {'units_layer1': 192, 'units_layer2': 96, 'dropout_rate': 0.5, 'learning_rate': 0.03339127779807053, 'batch_size': 16}. Best is trial 24 with value: -0.01549999974668026.\n",
      "[I 2024-11-27 21:51:32,845] Trial 25 finished with value: -0.008999999612569809 and parameters: {'units_layer1': 192, 'units_layer2': 96, 'dropout_rate': 0.4, 'learning_rate': 0.03657781900994454, 'batch_size': 16}. Best is trial 24 with value: -0.01549999974668026.\n",
      "[I 2024-11-27 21:51:56,525] Trial 26 finished with value: -0.008999999612569809 and parameters: {'units_layer1': 224, 'units_layer2': 96, 'dropout_rate': 0.30000000000000004, 'learning_rate': 0.050929386084689714, 'batch_size': 16}. Best is trial 24 with value: -0.01549999974668026.\n",
      "[I 2024-11-27 21:52:20,635] Trial 27 finished with value: -0.011500000022351742 and parameters: {'units_layer1': 256, 'units_layer2': 112, 'dropout_rate': 0.5, 'learning_rate': 0.0674506382840481, 'batch_size': 16}. Best is trial 24 with value: -0.01549999974668026.\n",
      "[I 2024-11-27 21:52:32,605] Trial 28 finished with value: -0.008500000461935997 and parameters: {'units_layer1': 192, 'units_layer2': 96, 'dropout_rate': 0.4, 'learning_rate': 0.026244260484674525, 'batch_size': 32}. Best is trial 24 with value: -0.01549999974668026.\n",
      "[I 2024-11-27 21:52:39,916] Trial 29 finished with value: -0.007000000216066837 and parameters: {'units_layer1': 224, 'units_layer2': 96, 'dropout_rate': 0.2, 'learning_rate': 0.021514357919901295, 'batch_size': 64}. Best is trial 24 with value: -0.01549999974668026.\n",
      "[I 2024-11-27 21:53:00,554] Trial 30 finished with value: -0.008500000461935997 and parameters: {'units_layer1': 192, 'units_layer2': 64, 'dropout_rate': 0.2, 'learning_rate': 0.003455756502095448, 'batch_size': 16}. Best is trial 24 with value: -0.01549999974668026.\n",
      "[I 2024-11-27 21:53:18,015] Trial 31 finished with value: -0.008500000461935997 and parameters: {'units_layer1': 160, 'units_layer2': 80, 'dropout_rate': 0.5, 'learning_rate': 0.013909732076678179, 'batch_size': 16}. Best is trial 24 with value: -0.01549999974668026.\n",
      "[I 2024-11-27 21:53:32,449] Trial 32 finished with value: -0.007499999832361937 and parameters: {'units_layer1': 160, 'units_layer2': 80, 'dropout_rate': 0.5, 'learning_rate': 0.007751245848042139, 'batch_size': 16}. Best is trial 24 with value: -0.01549999974668026.\n",
      "[I 2024-11-27 21:53:46,657] Trial 33 finished with value: -0.008500000461935997 and parameters: {'units_layer1': 160, 'units_layer2': 80, 'dropout_rate': 0.5, 'learning_rate': 0.03354129936810035, 'batch_size': 16}. Best is trial 24 with value: -0.01549999974668026.\n",
      "[I 2024-11-27 21:54:01,904] Trial 34 finished with value: -0.009999999776482582 and parameters: {'units_layer1': 192, 'units_layer2': 64, 'dropout_rate': 0.5, 'learning_rate': 0.0024230302262709686, 'batch_size': 16}. Best is trial 24 with value: -0.01549999974668026.\n",
      "[I 2024-11-27 21:54:20,508] Trial 35 finished with value: -0.008500000461935997 and parameters: {'units_layer1': 160, 'units_layer2': 64, 'dropout_rate': 0.4, 'learning_rate': 0.0010551163983356213, 'batch_size': 16}. Best is trial 24 with value: -0.01549999974668026.\n",
      "[I 2024-11-27 21:54:26,175] Trial 36 finished with value: -0.008500000461935997 and parameters: {'units_layer1': 128, 'units_layer2': 80, 'dropout_rate': 0.30000000000000004, 'learning_rate': 0.009763140513191012, 'batch_size': 64}. Best is trial 24 with value: -0.01549999974668026.\n",
      "[I 2024-11-27 21:54:44,280] Trial 37 finished with value: -0.008500000461935997 and parameters: {'units_layer1': 160, 'units_layer2': 128, 'dropout_rate': 0.4, 'learning_rate': 0.01757932228266051, 'batch_size': 16}. Best is trial 24 with value: -0.01549999974668026.\n",
      "[I 2024-11-27 21:54:49,787] Trial 38 finished with value: -0.009999999776482582 and parameters: {'units_layer1': 128, 'units_layer2': 80, 'dropout_rate': 0.5, 'learning_rate': 0.009887598412287335, 'batch_size': 64}. Best is trial 24 with value: -0.01549999974668026.\n",
      "[I 2024-11-27 21:55:10,711] Trial 39 finished with value: -0.008500000461935997 and parameters: {'units_layer1': 256, 'units_layer2': 64, 'dropout_rate': 0.1, 'learning_rate': 0.004588869538425916, 'batch_size': 16}. Best is trial 24 with value: -0.01549999974668026.\n",
      "[I 2024-11-27 21:55:22,126] Trial 40 finished with value: -0.010499999858438969 and parameters: {'units_layer1': 224, 'units_layer2': 112, 'dropout_rate': 0.30000000000000004, 'learning_rate': 0.0023743309702509994, 'batch_size': 32}. Best is trial 24 with value: -0.01549999974668026.\n",
      "[I 2024-11-27 21:55:42,865] Trial 41 finished with value: -0.011500000022351742 and parameters: {'units_layer1': 256, 'units_layer2': 112, 'dropout_rate': 0.5, 'learning_rate': 0.06712910132309302, 'batch_size': 16}. Best is trial 24 with value: -0.01549999974668026.\n",
      "[I 2024-11-27 21:56:02,983] Trial 42 finished with value: -0.010999999940395355 and parameters: {'units_layer1': 256, 'units_layer2': 112, 'dropout_rate': 0.5, 'learning_rate': 0.07482132849309707, 'batch_size': 16}. Best is trial 24 with value: -0.01549999974668026.\n",
      "[I 2024-11-27 21:56:19,909] Trial 43 finished with value: -0.007499999832361937 and parameters: {'units_layer1': 256, 'units_layer2': 128, 'dropout_rate': 0.5, 'learning_rate': 0.04847686117149965, 'batch_size': 16}. Best is trial 24 with value: -0.01549999974668026.\n",
      "[I 2024-11-27 21:56:36,727] Trial 44 finished with value: -0.00800000037997961 and parameters: {'units_layer1': 256, 'units_layer2': 96, 'dropout_rate': 0.4, 'learning_rate': 0.026882778646965644, 'batch_size': 16}. Best is trial 24 with value: -0.01549999974668026.\n",
      "[I 2024-11-27 21:56:42,208] Trial 45 finished with value: -0.008500000461935997 and parameters: {'units_layer1': 224, 'units_layer2': 112, 'dropout_rate': 0.5, 'learning_rate': 0.09543061326413288, 'batch_size': 64}. Best is trial 24 with value: -0.01549999974668026.\n",
      "[I 2024-11-27 21:57:01,630] Trial 46 finished with value: -0.008999999612569809 and parameters: {'units_layer1': 256, 'units_layer2': 128, 'dropout_rate': 0.5, 'learning_rate': 0.04069303998838582, 'batch_size': 16}. Best is trial 24 with value: -0.01549999974668026.\n",
      "[I 2024-11-27 21:57:22,200] Trial 47 finished with value: -0.009499999694526196 and parameters: {'units_layer1': 224, 'units_layer2': 96, 'dropout_rate': 0.4, 'learning_rate': 0.059674873460744605, 'batch_size': 16}. Best is trial 24 with value: -0.01549999974668026.\n",
      "[I 2024-11-27 21:57:28,672] Trial 48 finished with value: -0.013000000268220901 and parameters: {'units_layer1': 192, 'units_layer2': 112, 'dropout_rate': 0.5, 'learning_rate': 0.006465450106987815, 'batch_size': 64}. Best is trial 24 with value: -0.01549999974668026.\n",
      "[I 2024-11-27 21:57:36,611] Trial 49 finished with value: -0.017000000923871994 and parameters: {'units_layer1': 192, 'units_layer2': 112, 'dropout_rate': 0.1, 'learning_rate': 0.00679556834922299, 'batch_size': 64}. Best is trial 49 with value: -0.017000000923871994.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters: {'units_layer1': 192, 'units_layer2': 112, 'dropout_rate': 0.1, 'learning_rate': 0.00679556834922299, 'batch_size': 64}\n",
      "Best validation accuracy: 0.0170\n"
     ]
    }
   ],
   "source": [
    "# Create a study and optimize the objective function\n",
    "study = optuna.create_study(direction=\"minimize\")\n",
    "study.optimize(objective, n_trials=50)  # Run 50 trials\n",
    "\n",
    "best_params = study.best_params\n",
    "best_accuracy = -study.best_value  # Negate the value to get accuracy\n",
    "print(f\"Best parameters: {best_params}\")\n",
    "print(f\"Best validation accuracy: {best_accuracy:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters: {'units_layer1': 192, 'units_layer2': 112, 'dropout_rate': 0.1, 'learning_rate': 0.00679556834922299, 'batch_size': 64}\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\JZ\\AppData\\Roaming\\Python\\Python312\\site-packages\\keras\\src\\layers\\reshaping\\flatten.py:37: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n",
      "C:\\Users\\JZ\\AppData\\Roaming\\Python\\Python312\\site-packages\\keras\\src\\losses\\losses.py:27: SyntaxWarning: In loss categorical_crossentropy, expected y_pred.shape to be (batch_size, num_classes) with num_classes > 1. Received: y_pred.shape=(None, 1). Consider using 'binary_crossentropy' if you only have 2 classes.\n",
      "  return self.fn(y_true, y_pred, **self._fn_kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.0099 - loss: 1.0656e-06 - val_accuracy: 0.0085 - val_loss: 1.0505e-06\n",
      "Epoch 2/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.0106 - loss: 1.0649e-06 - val_accuracy: 0.0085 - val_loss: 1.0505e-06\n",
      "Epoch 3/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.0105 - loss: 1.0584e-06 - val_accuracy: 0.0085 - val_loss: 1.0505e-06\n",
      "Epoch 4/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.0117 - loss: 1.0626e-06 - val_accuracy: 0.0085 - val_loss: 1.0505e-06\n",
      "Epoch 5/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.0106 - loss: 1.0562e-06 - val_accuracy: 0.0085 - val_loss: 1.0505e-06\n",
      "Epoch 6/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.0105 - loss: 1.0516e-06 - val_accuracy: 0.0085 - val_loss: 1.0505e-06\n",
      "Epoch 7/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.0111 - loss: 1.0671e-06 - val_accuracy: 0.0085 - val_loss: 1.0505e-06\n",
      "Epoch 8/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.0117 - loss: 1.0648e-06 - val_accuracy: 0.0085 - val_loss: 1.0505e-06\n",
      "Epoch 9/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.0113 - loss: 1.0673e-06 - val_accuracy: 0.0085 - val_loss: 1.0505e-06\n",
      "Epoch 10/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.0091 - loss: 1.0607e-06 - val_accuracy: 0.0085 - val_loss: 1.0505e-06\n",
      "Epoch 11/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.0112 - loss: 1.0556e-06 - val_accuracy: 0.0085 - val_loss: 1.0505e-06\n",
      "Epoch 12/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.0097 - loss: 1.0648e-06 - val_accuracy: 0.0085 - val_loss: 1.0505e-06\n",
      "Epoch 13/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.0097 - loss: 1.0621e-06 - val_accuracy: 0.0085 - val_loss: 1.0505e-06\n",
      "Epoch 14/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.0102 - loss: 1.0597e-06 - val_accuracy: 0.0085 - val_loss: 1.0505e-06\n",
      "Epoch 15/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.0091 - loss: 1.0676e-06 - val_accuracy: 0.0085 - val_loss: 1.0505e-06\n",
      "Epoch 16/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.0112 - loss: 1.0697e-06 - val_accuracy: 0.0085 - val_loss: 1.0505e-06\n",
      "Epoch 17/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.0115 - loss: 1.0681e-06 - val_accuracy: 0.0085 - val_loss: 1.0505e-06\n",
      "Epoch 18/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.0116 - loss: 1.0574e-06 - val_accuracy: 0.0085 - val_loss: 1.0505e-06\n",
      "Epoch 19/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.0125 - loss: 1.0561e-06 - val_accuracy: 0.0085 - val_loss: 1.0505e-06\n",
      "Epoch 20/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.0111 - loss: 1.0661e-06 - val_accuracy: 0.0085 - val_loss: 1.0505e-06\n",
      "Epoch 21/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.0104 - loss: 1.0648e-06 - val_accuracy: 0.0085 - val_loss: 1.0505e-06\n",
      "Epoch 22/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.0100 - loss: 1.0619e-06 - val_accuracy: 0.0085 - val_loss: 1.0505e-06\n",
      "Epoch 23/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.0120 - loss: 1.0529e-06 - val_accuracy: 0.0085 - val_loss: 1.0505e-06\n",
      "Epoch 24/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.0098 - loss: 1.0655e-06 - val_accuracy: 0.0085 - val_loss: 1.0505e-06\n",
      "Epoch 25/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.0111 - loss: 1.0579e-06 - val_accuracy: 0.0085 - val_loss: 1.0505e-06\n",
      "Epoch 26/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.0113 - loss: 1.0534e-06 - val_accuracy: 0.0085 - val_loss: 1.0505e-06\n",
      "Epoch 27/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.0107 - loss: 1.0571e-06 - val_accuracy: 0.0085 - val_loss: 1.0505e-06\n",
      "Epoch 28/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.0114 - loss: 1.0571e-06 - val_accuracy: 0.0085 - val_loss: 1.0505e-06\n",
      "Epoch 29/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.0110 - loss: 1.0580e-06 - val_accuracy: 0.0085 - val_loss: 1.0505e-06\n",
      "Epoch 30/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.0084 - loss: 1.0640e-06 - val_accuracy: 0.0085 - val_loss: 1.0505e-06\n",
      "Epoch 31/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.0102 - loss: 1.0650e-06 - val_accuracy: 0.0085 - val_loss: 1.0505e-06\n",
      "Epoch 32/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.0105 - loss: 1.0613e-06 - val_accuracy: 0.0085 - val_loss: 1.0505e-06\n",
      "Epoch 33/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.0091 - loss: 1.0709e-06 - val_accuracy: 0.0085 - val_loss: 1.0505e-06\n",
      "Epoch 34/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.0112 - loss: 1.0601e-06 - val_accuracy: 0.0085 - val_loss: 1.0505e-06\n",
      "Epoch 35/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.0106 - loss: 1.0647e-06 - val_accuracy: 0.0085 - val_loss: 1.0505e-06\n",
      "Epoch 36/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.0084 - loss: 1.0673e-06 - val_accuracy: 0.0085 - val_loss: 1.0505e-06\n",
      "Epoch 37/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.0124 - loss: 1.0620e-06 - val_accuracy: 0.0085 - val_loss: 1.0505e-06\n",
      "Epoch 38/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.0103 - loss: 1.0658e-06 - val_accuracy: 0.0085 - val_loss: 1.0505e-06\n",
      "Epoch 39/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.0102 - loss: 1.0559e-06 - val_accuracy: 0.0085 - val_loss: 1.0505e-06\n",
      "Epoch 40/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.0101 - loss: 1.0620e-06 - val_accuracy: 0.0085 - val_loss: 1.0505e-06\n",
      "Epoch 41/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.0125 - loss: 1.0569e-06 - val_accuracy: 0.0085 - val_loss: 1.0505e-06\n",
      "Epoch 42/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.0110 - loss: 1.0632e-06 - val_accuracy: 0.0085 - val_loss: 1.0505e-06\n",
      "Epoch 43/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.0109 - loss: 1.0594e-06 - val_accuracy: 0.0085 - val_loss: 1.0505e-06\n",
      "Epoch 44/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.0099 - loss: 1.0678e-06 - val_accuracy: 0.0085 - val_loss: 1.0505e-06\n",
      "Epoch 45/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.0118 - loss: 1.0600e-06 - val_accuracy: 0.0085 - val_loss: 1.0505e-06\n",
      "Epoch 46/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.0107 - loss: 1.0665e-06 - val_accuracy: 0.0085 - val_loss: 1.0505e-06\n",
      "Epoch 47/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.0113 - loss: 1.0571e-06 - val_accuracy: 0.0085 - val_loss: 1.0505e-06\n",
      "Epoch 48/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.0117 - loss: 1.0590e-06 - val_accuracy: 0.0085 - val_loss: 1.0505e-06\n",
      "Epoch 49/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.0103 - loss: 1.0610e-06 - val_accuracy: 0.0085 - val_loss: 1.0505e-06\n",
      "Epoch 50/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.0117 - loss: 1.0658e-06 - val_accuracy: 0.0085 - val_loss: 1.0505e-06\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 839us/step - accuracy: 0.0131 - loss: 1.0511e-06\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.056343421623751e-06, 0.013000000268220901]"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Get the best parameters\n",
    "best_params = study.best_params\n",
    "print(f\"Best parameters: {best_params}\")\n",
    "\n",
    "# Build the best model with the optimized parameters\n",
    "best_model = Sequential([\n",
    "    Flatten(input_shape=(56, 28, 1)),\n",
    "    Dense(best_params['units_layer1'], activation='relu'),\n",
    "    Dropout(best_params['dropout_rate']),\n",
    "    Dense(best_params['units_layer2'], activation='relu'),\n",
    "    Dense(1)\n",
    "])\n",
    "\n",
    "best_model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=best_params['learning_rate']),\n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "# Train the best model on the full training set\n",
    "best_model.fit(\n",
    "    train_images, train_labels,\n",
    "    validation_data=(val_images, val_labels),\n",
    "    epochs=50,\n",
    "    batch_size=best_params['batch_size']\n",
    ")\n",
    "\n",
    "best_model.evaluate(test_images, test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
